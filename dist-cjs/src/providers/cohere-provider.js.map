{"version":3,"sources":["../../../src/providers/cohere-provider.ts"],"sourcesContent":["/**\r\n * Cohere Provider Implementation\r\n * Supports Command, Generate, and other Cohere models\r\n */\r\n\r\nimport { BaseProvider } from './base-provider.js';\r\nimport {\r\n  LLMProvider,\r\n  LLMModel,\r\n  LLMRequest,\r\n  LLMResponse,\r\n  LLMStreamEvent,\r\n  ModelInfo,\r\n  ProviderCapabilities,\r\n  HealthCheckResult,\r\n  LLMProviderError,\r\n  RateLimitError,\r\n  AuthenticationError,\r\n} from './types.js';\r\n\r\ninterface CohereGenerateRequest {\r\n  model: string;\r\n  prompt?: string;\r\n  messages?: Array<{\r\n    role: 'USER' | 'CHATBOT' | 'SYSTEM';\r\n    message: string;\r\n  }>;\r\n  preamble?: string;\r\n  temperature?: number;\r\n  max_tokens?: number;\r\n  k?: number;\r\n  p?: number;\r\n  frequency_penalty?: number;\r\n  presence_penalty?: number;\r\n  stop_sequences?: string[];\r\n  stream?: boolean;\r\n}\r\n\r\ninterface CohereGenerateResponse {\r\n  id: string;\r\n  generations: Array<{\r\n    id: string;\r\n    text: string;\r\n    finish_reason: string;\r\n  }>;\r\n  prompt: string;\r\n  meta: {\r\n    api_version: {\r\n      version: string;\r\n    };\r\n    billed_units: {\r\n      input_tokens: number;\r\n      output_tokens: number;\r\n    };\r\n  };\r\n}\r\n\r\ninterface CohereChatResponse {\r\n  text: string;\r\n  generation_id: string;\r\n  finish_reason: string;\r\n  meta: {\r\n    api_version: {\r\n      version: string;\r\n    };\r\n    billed_units: {\r\n      input_tokens: number;\r\n      output_tokens: number;\r\n    };\r\n  };\r\n}\r\n\r\nexport class CohereProvider extends BaseProvider {\r\n  readonly name: LLMProvider = 'cohere';\r\n  readonly capabilities: ProviderCapabilities = {\r\n    supportedModels: [\r\n      'command',\r\n      'command-light',\r\n      'command-nightly',\r\n      'generate-xlarge',\r\n      'generate-medium',\r\n    ],\r\n    maxContextLength: {\r\n      'command': 4096,\r\n      'command-light': 4096,\r\n      'command-nightly': 8192,\r\n      'generate-xlarge': 2048,\r\n      'generate-medium': 2048,\r\n    } as Record<LLMModel, number>,\r\n    maxOutputTokens: {\r\n      'command': 4096,\r\n      'command-light': 4096,\r\n      'command-nightly': 4096,\r\n      'generate-xlarge': 2048,\r\n      'generate-medium': 2048,\r\n    } as Record<LLMModel, number>,\r\n    supportsStreaming: true,\r\n    supportsFunctionCalling: false,\r\n    supportsSystemMessages: true,\r\n    supportsVision: false,\r\n    supportsAudio: false,\r\n    supportsTools: true,\r\n    supportsFineTuning: true,\r\n    supportsEmbeddings: true,\r\n    supportsLogprobs: true,\r\n    supportsBatching: false,\r\n    rateLimit: {\r\n      requestsPerMinute: 100,\r\n      tokensPerMinute: 100000,\r\n      concurrentRequests: 20,\r\n    },\r\n    pricing: {\r\n      'command': {\r\n        promptCostPer1k: 0.0015,\r\n        completionCostPer1k: 0.0015,\r\n        currency: 'USD',\r\n      },\r\n      'command-light': {\r\n        promptCostPer1k: 0.00015,\r\n        completionCostPer1k: 0.00015,\r\n        currency: 'USD',\r\n      },\r\n      'command-nightly': {\r\n        promptCostPer1k: 0.0015,\r\n        completionCostPer1k: 0.0015,\r\n        currency: 'USD',\r\n      },\r\n      'generate-xlarge': {\r\n        promptCostPer1k: 0.005,\r\n        completionCostPer1k: 0.015,\r\n        currency: 'USD',\r\n      },\r\n      'generate-medium': {\r\n        promptCostPer1k: 0.001,\r\n        completionCostPer1k: 0.005,\r\n        currency: 'USD',\r\n      },\r\n    },\r\n  };\r\n\r\n  private baseUrl = 'https://api.cohere.ai/v1';\r\n  private headers: Record<string, string> = {};\r\n\r\n  protected async doInitialize(): Promise<void> {\r\n    if (!this.config.apiKey) {\r\n      throw new AuthenticationError('Cohere API key is required', 'cohere');\r\n    }\r\n\r\n    this.headers = {\r\n      'Authorization': `Bearer ${this.config.apiKey}`,\r\n      'Content-Type': 'application/json',\r\n      'Accept': 'application/json',\r\n    };\r\n  }\r\n\r\n  protected async doComplete(request: LLMRequest): Promise<LLMResponse> {\r\n    const isChat = request.messages.length > 1 || request.messages[0].role !== 'user';\r\n    const model = request.model || this.config.model;\r\n    \r\n    if (isChat && model.startsWith('command')) {\r\n      return this.doChatComplete(request);\r\n    } else {\r\n      return this.doGenerateComplete(request);\r\n    }\r\n  }\r\n\r\n  private async doChatComplete(request: LLMRequest): Promise<LLMResponse> {\r\n    const messages = this.convertMessages(request.messages);\r\n    const systemMessage = request.messages.find(m => m.role === 'system');\r\n    \r\n    const cohereRequest = {\r\n      model: this.mapToCohereModel(request.model || this.config.model),\r\n      messages,\r\n      preamble: systemMessage?.content,\r\n      temperature: request.temperature ?? this.config.temperature,\r\n      max_tokens: request.maxTokens ?? this.config.maxTokens,\r\n      k: request.topK ?? this.config.topK,\r\n      p: request.topP ?? this.config.topP,\r\n      frequency_penalty: request.frequencyPenalty ?? this.config.frequencyPenalty,\r\n      presence_penalty: request.presencePenalty ?? this.config.presencePenalty,\r\n      stop_sequences: request.stopSequences ?? this.config.stopSequences,\r\n      stream: false,\r\n    };\r\n\r\n    const controller = new AbortController();\r\n    const timeout = setTimeout(() => controller.abort(), this.config.timeout || 60000);\r\n\r\n    try {\r\n      const response = await fetch(`${this.baseUrl}/chat`, {\r\n        method: 'POST',\r\n        headers: this.headers,\r\n        body: JSON.stringify(cohereRequest),\r\n        signal: controller.signal,\r\n      });\r\n\r\n      clearTimeout(timeout);\r\n\r\n      if (!response.ok) {\r\n        await this.handleErrorResponse(response);\r\n      }\r\n\r\n      const data: CohereChatResponse = await response.json();\r\n      \r\n      // Calculate cost\r\n      const pricing = this.capabilities.pricing![request.model || this.config.model];\r\n      const promptCost = (data.meta.billed_units.input_tokens / 1000) * pricing.promptCostPer1k;\r\n      const completionCost = (data.meta.billed_units.output_tokens / 1000) * pricing.completionCostPer1k;\r\n\r\n      return {\r\n        id: data.generation_id,\r\n        model: request.model || this.config.model,\r\n        provider: 'cohere',\r\n        content: data.text,\r\n        usage: {\r\n          promptTokens: data.meta.billed_units.input_tokens,\r\n          completionTokens: data.meta.billed_units.output_tokens,\r\n          totalTokens: data.meta.billed_units.input_tokens + data.meta.billed_units.output_tokens,\r\n        },\r\n        cost: {\r\n          promptCost,\r\n          completionCost,\r\n          totalCost: promptCost + completionCost,\r\n          currency: 'USD',\r\n        },\r\n        finishReason: this.mapFinishReason(data.finish_reason),\r\n      };\r\n    } catch (error) {\r\n      clearTimeout(timeout);\r\n      throw this.transformError(error);\r\n    }\r\n  }\r\n\r\n  private async doGenerateComplete(request: LLMRequest): Promise<LLMResponse> {\r\n    // For generate endpoint, concatenate messages into a prompt\r\n    const prompt = request.messages.map(m => m.content).join('\\n\\n');\r\n    \r\n    const cohereRequest: CohereGenerateRequest = {\r\n      model: this.mapToCohereModel(request.model || this.config.model),\r\n      prompt,\r\n      temperature: request.temperature ?? this.config.temperature,\r\n      max_tokens: request.maxTokens ?? this.config.maxTokens,\r\n      k: request.topK ?? this.config.topK,\r\n      p: request.topP ?? this.config.topP,\r\n      frequency_penalty: request.frequencyPenalty ?? this.config.frequencyPenalty,\r\n      presence_penalty: request.presencePenalty ?? this.config.presencePenalty,\r\n      stop_sequences: request.stopSequences ?? this.config.stopSequences,\r\n      stream: false,\r\n    };\r\n\r\n    const controller = new AbortController();\r\n    const timeout = setTimeout(() => controller.abort(), this.config.timeout || 60000);\r\n\r\n    try {\r\n      const response = await fetch(`${this.baseUrl}/generate`, {\r\n        method: 'POST',\r\n        headers: this.headers,\r\n        body: JSON.stringify(cohereRequest),\r\n        signal: controller.signal,\r\n      });\r\n\r\n      clearTimeout(timeout);\r\n\r\n      if (!response.ok) {\r\n        await this.handleErrorResponse(response);\r\n      }\r\n\r\n      const data: CohereGenerateResponse = await response.json();\r\n      const generation = data.generations[0];\r\n      \r\n      // Calculate cost\r\n      const pricing = this.capabilities.pricing![request.model || this.config.model];\r\n      const promptCost = (data.meta.billed_units.input_tokens / 1000) * pricing.promptCostPer1k;\r\n      const completionCost = (data.meta.billed_units.output_tokens / 1000) * pricing.completionCostPer1k;\r\n\r\n      return {\r\n        id: generation.id,\r\n        model: request.model || this.config.model,\r\n        provider: 'cohere',\r\n        content: generation.text,\r\n        usage: {\r\n          promptTokens: data.meta.billed_units.input_tokens,\r\n          completionTokens: data.meta.billed_units.output_tokens,\r\n          totalTokens: data.meta.billed_units.input_tokens + data.meta.billed_units.output_tokens,\r\n        },\r\n        cost: {\r\n          promptCost,\r\n          completionCost,\r\n          totalCost: promptCost + completionCost,\r\n          currency: 'USD',\r\n        },\r\n        finishReason: this.mapFinishReason(generation.finish_reason),\r\n      };\r\n    } catch (error) {\r\n      clearTimeout(timeout);\r\n      throw this.transformError(error);\r\n    }\r\n  }\r\n\r\n  protected async *doStreamComplete(request: LLMRequest): AsyncIterable<LLMStreamEvent> {\r\n    const isChat = request.messages.length > 1 || request.messages[0].role !== 'user';\r\n    const model = request.model || this.config.model;\r\n    \r\n    if (isChat && model.startsWith('command')) {\r\n      yield* this.streamChatComplete(request);\r\n    } else {\r\n      yield* this.streamGenerateComplete(request);\r\n    }\r\n  }\r\n\r\n  private async *streamChatComplete(request: LLMRequest): AsyncIterable<LLMStreamEvent> {\r\n    const messages = this.convertMessages(request.messages);\r\n    const systemMessage = request.messages.find(m => m.role === 'system');\r\n    \r\n    const cohereRequest = {\r\n      model: this.mapToCohereModel(request.model || this.config.model),\r\n      messages,\r\n      preamble: systemMessage?.content,\r\n      temperature: request.temperature ?? this.config.temperature,\r\n      max_tokens: request.maxTokens ?? this.config.maxTokens,\r\n      k: request.topK ?? this.config.topK,\r\n      p: request.topP ?? this.config.topP,\r\n      frequency_penalty: request.frequencyPenalty ?? this.config.frequencyPenalty,\r\n      presence_penalty: request.presencePenalty ?? this.config.presencePenalty,\r\n      stop_sequences: request.stopSequences ?? this.config.stopSequences,\r\n      stream: true,\r\n    };\r\n\r\n    const controller = new AbortController();\r\n    const timeout = setTimeout(() => controller.abort(), (this.config.timeout || 60000) * 2);\r\n\r\n    try {\r\n      const response = await fetch(`${this.baseUrl}/chat`, {\r\n        method: 'POST',\r\n        headers: this.headers,\r\n        body: JSON.stringify(cohereRequest),\r\n        signal: controller.signal,\r\n      });\r\n\r\n      if (!response.ok) {\r\n        await this.handleErrorResponse(response);\r\n      }\r\n\r\n      const reader = response.body!.getReader();\r\n      const decoder = new TextDecoder();\r\n      let buffer = '';\r\n      let totalContent = '';\r\n\r\n      while (true) {\r\n        const { done, value } = await reader.read();\r\n        if (done) break;\r\n\r\n        buffer += decoder.decode(value, { stream: true });\r\n        const lines = buffer.split('\\n');\r\n        buffer = lines.pop() || '';\r\n\r\n        for (const line of lines) {\r\n          if (line.trim() === '') continue;\r\n          \r\n          try {\r\n            const data = JSON.parse(line);\r\n            \r\n            if (data.text) {\r\n              totalContent += data.text;\r\n              yield {\r\n                type: 'content',\r\n                delta: { content: data.text },\r\n              };\r\n            }\r\n            \r\n            if (data.is_finished) {\r\n              // Estimate tokens for streaming\r\n              const promptTokens = this.estimateTokens(JSON.stringify(request.messages));\r\n              const completionTokens = this.estimateTokens(totalContent);\r\n              \r\n              const pricing = this.capabilities.pricing![request.model || this.config.model];\r\n              const promptCost = (promptTokens / 1000) * pricing.promptCostPer1k;\r\n              const completionCost = (completionTokens / 1000) * pricing.completionCostPer1k;\r\n\r\n              yield {\r\n                type: 'done',\r\n                usage: {\r\n                  promptTokens,\r\n                  completionTokens,\r\n                  totalTokens: promptTokens + completionTokens,\r\n                },\r\n                cost: {\r\n                  promptCost,\r\n                  completionCost,\r\n                  totalCost: promptCost + completionCost,\r\n                  currency: 'USD',\r\n                },\r\n              };\r\n            }\r\n          } catch (e) {\r\n            this.logger.warn('Failed to parse Cohere stream chunk', { line, error: e });\r\n          }\r\n        }\r\n      }\r\n    } catch (error) {\r\n      clearTimeout(timeout);\r\n      throw this.transformError(error);\r\n    } finally {\r\n      clearTimeout(timeout);\r\n    }\r\n  }\r\n\r\n  private async *streamGenerateComplete(request: LLMRequest): AsyncIterable<LLMStreamEvent> {\r\n    // Similar implementation for generate endpoint\r\n    // Omitted for brevity - follows same pattern as streamChatComplete\r\n    yield* this.streamChatComplete(request); // Fallback to chat for now\r\n  }\r\n\r\n  async listModels(): Promise<LLMModel[]> {\r\n    return this.capabilities.supportedModels;\r\n  }\r\n\r\n  async getModelInfo(model: LLMModel): Promise<ModelInfo> {\r\n    return {\r\n      model,\r\n      name: model,\r\n      description: this.getModelDescription(model),\r\n      contextLength: this.capabilities.maxContextLength[model] || 4096,\r\n      maxOutputTokens: this.capabilities.maxOutputTokens[model] || 4096,\r\n      supportedFeatures: [\r\n        'chat',\r\n        'completion',\r\n        'embeddings',\r\n        ...(model.startsWith('command') ? ['tools'] : []),\r\n      ],\r\n      pricing: this.capabilities.pricing![model],\r\n    };\r\n  }\r\n\r\n  protected async doHealthCheck(): Promise<HealthCheckResult> {\r\n    try {\r\n      const response = await fetch(`${this.baseUrl}/check-api-key`, {\r\n        method: 'POST',\r\n        headers: this.headers,\r\n      });\r\n\r\n      if (!response.ok) {\r\n        throw new Error(`Health check failed: ${response.status}`);\r\n      }\r\n\r\n      return {\r\n        healthy: true,\r\n        timestamp: new Date(),\r\n      };\r\n    } catch (error) {\r\n      return {\r\n        healthy: false,\r\n        error: error instanceof Error ? error.message : 'Unknown error',\r\n        timestamp: new Date(),\r\n      };\r\n    }\r\n  }\r\n\r\n  private convertMessages(messages: LLMRequest['messages']) {\r\n    return messages\r\n      .filter(m => m.role !== 'system')\r\n      .map(m => ({\r\n        role: m.role === 'assistant' ? 'CHATBOT' as const : 'USER' as const,\r\n        message: m.content,\r\n      }));\r\n  }\r\n\r\n  private mapToCohereModel(model: LLMModel): string {\r\n    const modelMap: Record<string, string> = {\r\n      'command': 'command',\r\n      'command-light': 'command-light',\r\n      'command-nightly': 'command-nightly',\r\n      'generate-xlarge': 'xlarge',\r\n      'generate-medium': 'medium',\r\n    };\r\n    return modelMap[model] || model;\r\n  }\r\n\r\n  private mapFinishReason(reason: string): 'stop' | 'length' {\r\n    return reason === 'COMPLETE' ? 'stop' : 'length';\r\n  }\r\n\r\n  private getModelDescription(model: LLMModel): string {\r\n    const descriptions: Record<string, string> = {\r\n      'command': 'Powerful model for complex tasks',\r\n      'command-light': 'Faster, lightweight version of Command',\r\n      'command-nightly': 'Latest experimental Command model',\r\n      'generate-xlarge': 'Large generation model',\r\n      'generate-medium': 'Medium generation model',\r\n    };\r\n    return descriptions[model] || 'Cohere language model';\r\n  }\r\n\r\n  private async handleErrorResponse(response: Response): Promise<void> {\r\n    const errorText = await response.text();\r\n    let errorData: any;\r\n\r\n    try {\r\n      errorData = JSON.parse(errorText);\r\n    } catch {\r\n      errorData = { message: errorText };\r\n    }\r\n\r\n    const message = errorData.message || 'Unknown error';\r\n\r\n    switch (response.status) {\r\n      case 401:\r\n        throw new AuthenticationError(message, 'cohere', errorData);\r\n      case 429:\r\n        throw new RateLimitError(message, 'cohere', undefined, errorData);\r\n      default:\r\n        throw new LLMProviderError(\r\n          message,\r\n          `COHERE_${response.status}`,\r\n          'cohere',\r\n          response.status,\r\n          response.status >= 500,\r\n          errorData\r\n        );\r\n    }\r\n  }\r\n}"],"names":["BaseProvider","LLMProviderError","RateLimitError","AuthenticationError","CohereProvider","name","capabilities","supportedModels","maxContextLength","maxOutputTokens","supportsStreaming","supportsFunctionCalling","supportsSystemMessages","supportsVision","supportsAudio","supportsTools","supportsFineTuning","supportsEmbeddings","supportsLogprobs","supportsBatching","rateLimit","requestsPerMinute","tokensPerMinute","concurrentRequests","pricing","promptCostPer1k","completionCostPer1k","currency","baseUrl","headers","doInitialize","config","apiKey","doComplete","request","isChat","messages","length","role","model","startsWith","doChatComplete","doGenerateComplete","convertMessages","systemMessage","find","m","cohereRequest","mapToCohereModel","preamble","content","temperature","max_tokens","maxTokens","k","topK","p","topP","frequency_penalty","frequencyPenalty","presence_penalty","presencePenalty","stop_sequences","stopSequences","stream","controller","AbortController","timeout","setTimeout","abort","response","fetch","method","body","JSON","stringify","signal","clearTimeout","ok","handleErrorResponse","data","json","promptCost","meta","billed_units","input_tokens","completionCost","output_tokens","id","generation_id","provider","text","usage","promptTokens","completionTokens","totalTokens","cost","totalCost","finishReason","mapFinishReason","finish_reason","error","transformError","prompt","map","join","generation","generations","doStreamComplete","streamChatComplete","streamGenerateComplete","reader","getReader","decoder","TextDecoder","buffer","totalContent","done","value","read","decode","lines","split","pop","line","trim","parse","type","delta","is_finished","estimateTokens","e","logger","warn","listModels","getModelInfo","description","getModelDescription","contextLength","supportedFeatures","doHealthCheck","Error","status","healthy","timestamp","Date","message","filter","modelMap","reason","descriptions","errorText","errorData","undefined"],"mappings":"AAKA,SAASA,YAAY,QAAQ,qBAAqB;AAClD,SASEC,gBAAgB,EAChBC,cAAc,EACdC,mBAAmB,QACd,aAAa;AAsDpB,OAAO,MAAMC,uBAAuBJ;IACzBK,OAAoB,SAAS;IAC7BC,eAAqC;QAC5CC,iBAAiB;YACf;YACA;YACA;YACA;YACA;SACD;QACDC,kBAAkB;YAChB,WAAW;YACX,iBAAiB;YACjB,mBAAmB;YACnB,mBAAmB;YACnB,mBAAmB;QACrB;QACAC,iBAAiB;YACf,WAAW;YACX,iBAAiB;YACjB,mBAAmB;YACnB,mBAAmB;YACnB,mBAAmB;QACrB;QACAC,mBAAmB;QACnBC,yBAAyB;QACzBC,wBAAwB;QACxBC,gBAAgB;QAChBC,eAAe;QACfC,eAAe;QACfC,oBAAoB;QACpBC,oBAAoB;QACpBC,kBAAkB;QAClBC,kBAAkB;QAClBC,WAAW;YACTC,mBAAmB;YACnBC,iBAAiB;YACjBC,oBAAoB;QACtB;QACAC,SAAS;YACP,WAAW;gBACTC,iBAAiB;gBACjBC,qBAAqB;gBACrBC,UAAU;YACZ;YACA,iBAAiB;gBACfF,iBAAiB;gBACjBC,qBAAqB;gBACrBC,UAAU;YACZ;YACA,mBAAmB;gBACjBF,iBAAiB;gBACjBC,qBAAqB;gBACrBC,UAAU;YACZ;YACA,mBAAmB;gBACjBF,iBAAiB;gBACjBC,qBAAqB;gBACrBC,UAAU;YACZ;YACA,mBAAmB;gBACjBF,iBAAiB;gBACjBC,qBAAqB;gBACrBC,UAAU;YACZ;QACF;IACF,EAAE;IAEMC,UAAU,2BAA2B;IACrCC,UAAkC,CAAC,EAAE;IAE7C,MAAgBC,eAA8B;QAC5C,IAAI,CAAC,IAAI,CAACC,MAAM,CAACC,MAAM,EAAE;YACvB,MAAM,IAAI7B,oBAAoB,8BAA8B;QAC9D;QAEA,IAAI,CAAC0B,OAAO,GAAG;YACb,iBAAiB,CAAC,OAAO,EAAE,IAAI,CAACE,MAAM,CAACC,MAAM,EAAE;YAC/C,gBAAgB;YAChB,UAAU;QACZ;IACF;IAEA,MAAgBC,WAAWC,OAAmB,EAAwB;QACpE,MAAMC,SAASD,QAAQE,QAAQ,CAACC,MAAM,GAAG,KAAKH,QAAQE,QAAQ,CAAC,EAAE,CAACE,IAAI,KAAK;QAC3E,MAAMC,QAAQL,QAAQK,KAAK,IAAI,IAAI,CAACR,MAAM,CAACQ,KAAK;QAEhD,IAAIJ,UAAUI,MAAMC,UAAU,CAAC,YAAY;YACzC,OAAO,IAAI,CAACC,cAAc,CAACP;QAC7B,OAAO;YACL,OAAO,IAAI,CAACQ,kBAAkB,CAACR;QACjC;IACF;IAEA,MAAcO,eAAeP,OAAmB,EAAwB;QACtE,MAAME,WAAW,IAAI,CAACO,eAAe,CAACT,QAAQE,QAAQ;QACtD,MAAMQ,gBAAgBV,QAAQE,QAAQ,CAACS,IAAI,CAACC,CAAAA,IAAKA,EAAER,IAAI,KAAK;QAE5D,MAAMS,gBAAgB;YACpBR,OAAO,IAAI,CAACS,gBAAgB,CAACd,QAAQK,KAAK,IAAI,IAAI,CAACR,MAAM,CAACQ,KAAK;YAC/DH;YACAa,UAAUL,eAAeM;YACzBC,aAAajB,QAAQiB,WAAW,IAAI,IAAI,CAACpB,MAAM,CAACoB,WAAW;YAC3DC,YAAYlB,QAAQmB,SAAS,IAAI,IAAI,CAACtB,MAAM,CAACsB,SAAS;YACtDC,GAAGpB,QAAQqB,IAAI,IAAI,IAAI,CAACxB,MAAM,CAACwB,IAAI;YACnCC,GAAGtB,QAAQuB,IAAI,IAAI,IAAI,CAAC1B,MAAM,CAAC0B,IAAI;YACnCC,mBAAmBxB,QAAQyB,gBAAgB,IAAI,IAAI,CAAC5B,MAAM,CAAC4B,gBAAgB;YAC3EC,kBAAkB1B,QAAQ2B,eAAe,IAAI,IAAI,CAAC9B,MAAM,CAAC8B,eAAe;YACxEC,gBAAgB5B,QAAQ6B,aAAa,IAAI,IAAI,CAAChC,MAAM,CAACgC,aAAa;YAClEC,QAAQ;QACV;QAEA,MAAMC,aAAa,IAAIC;QACvB,MAAMC,UAAUC,WAAW,IAAMH,WAAWI,KAAK,IAAI,IAAI,CAACtC,MAAM,CAACoC,OAAO,IAAI;QAE5E,IAAI;YACF,MAAMG,WAAW,MAAMC,MAAM,GAAG,IAAI,CAAC3C,OAAO,CAAC,KAAK,CAAC,EAAE;gBACnD4C,QAAQ;gBACR3C,SAAS,IAAI,CAACA,OAAO;gBACrB4C,MAAMC,KAAKC,SAAS,CAAC5B;gBACrB6B,QAAQX,WAAWW,MAAM;YAC3B;YAEAC,aAAaV;YAEb,IAAI,CAACG,SAASQ,EAAE,EAAE;gBAChB,MAAM,IAAI,CAACC,mBAAmB,CAACT;YACjC;YAEA,MAAMU,OAA2B,MAAMV,SAASW,IAAI;YAGpD,MAAMzD,UAAU,IAAI,CAAClB,YAAY,CAACkB,OAAO,AAAC,CAACU,QAAQK,KAAK,IAAI,IAAI,CAACR,MAAM,CAACQ,KAAK,CAAC;YAC9E,MAAM2C,aAAa,AAACF,KAAKG,IAAI,CAACC,YAAY,CAACC,YAAY,GAAG,OAAQ7D,QAAQC,eAAe;YACzF,MAAM6D,iBAAiB,AAACN,KAAKG,IAAI,CAACC,YAAY,CAACG,aAAa,GAAG,OAAQ/D,QAAQE,mBAAmB;YAElG,OAAO;gBACL8D,IAAIR,KAAKS,aAAa;gBACtBlD,OAAOL,QAAQK,KAAK,IAAI,IAAI,CAACR,MAAM,CAACQ,KAAK;gBACzCmD,UAAU;gBACVxC,SAAS8B,KAAKW,IAAI;gBAClBC,OAAO;oBACLC,cAAcb,KAAKG,IAAI,CAACC,YAAY,CAACC,YAAY;oBACjDS,kBAAkBd,KAAKG,IAAI,CAACC,YAAY,CAACG,aAAa;oBACtDQ,aAAaf,KAAKG,IAAI,CAACC,YAAY,CAACC,YAAY,GAAGL,KAAKG,IAAI,CAACC,YAAY,CAACG,aAAa;gBACzF;gBACAS,MAAM;oBACJd;oBACAI;oBACAW,WAAWf,aAAaI;oBACxB3D,UAAU;gBACZ;gBACAuE,cAAc,IAAI,CAACC,eAAe,CAACnB,KAAKoB,aAAa;YACvD;QACF,EAAE,OAAOC,OAAO;YACdxB,aAAaV;YACb,MAAM,IAAI,CAACmC,cAAc,CAACD;QAC5B;IACF;IAEA,MAAc3D,mBAAmBR,OAAmB,EAAwB;QAE1E,MAAMqE,SAASrE,QAAQE,QAAQ,CAACoE,GAAG,CAAC1D,CAAAA,IAAKA,EAAEI,OAAO,EAAEuD,IAAI,CAAC;QAEzD,MAAM1D,gBAAuC;YAC3CR,OAAO,IAAI,CAACS,gBAAgB,CAACd,QAAQK,KAAK,IAAI,IAAI,CAACR,MAAM,CAACQ,KAAK;YAC/DgE;YACApD,aAAajB,QAAQiB,WAAW,IAAI,IAAI,CAACpB,MAAM,CAACoB,WAAW;YAC3DC,YAAYlB,QAAQmB,SAAS,IAAI,IAAI,CAACtB,MAAM,CAACsB,SAAS;YACtDC,GAAGpB,QAAQqB,IAAI,IAAI,IAAI,CAACxB,MAAM,CAACwB,IAAI;YACnCC,GAAGtB,QAAQuB,IAAI,IAAI,IAAI,CAAC1B,MAAM,CAAC0B,IAAI;YACnCC,mBAAmBxB,QAAQyB,gBAAgB,IAAI,IAAI,CAAC5B,MAAM,CAAC4B,gBAAgB;YAC3EC,kBAAkB1B,QAAQ2B,eAAe,IAAI,IAAI,CAAC9B,MAAM,CAAC8B,eAAe;YACxEC,gBAAgB5B,QAAQ6B,aAAa,IAAI,IAAI,CAAChC,MAAM,CAACgC,aAAa;YAClEC,QAAQ;QACV;QAEA,MAAMC,aAAa,IAAIC;QACvB,MAAMC,UAAUC,WAAW,IAAMH,WAAWI,KAAK,IAAI,IAAI,CAACtC,MAAM,CAACoC,OAAO,IAAI;QAE5E,IAAI;YACF,MAAMG,WAAW,MAAMC,MAAM,GAAG,IAAI,CAAC3C,OAAO,CAAC,SAAS,CAAC,EAAE;gBACvD4C,QAAQ;gBACR3C,SAAS,IAAI,CAACA,OAAO;gBACrB4C,MAAMC,KAAKC,SAAS,CAAC5B;gBACrB6B,QAAQX,WAAWW,MAAM;YAC3B;YAEAC,aAAaV;YAEb,IAAI,CAACG,SAASQ,EAAE,EAAE;gBAChB,MAAM,IAAI,CAACC,mBAAmB,CAACT;YACjC;YAEA,MAAMU,OAA+B,MAAMV,SAASW,IAAI;YACxD,MAAMyB,aAAa1B,KAAK2B,WAAW,CAAC,EAAE;YAGtC,MAAMnF,UAAU,IAAI,CAAClB,YAAY,CAACkB,OAAO,AAAC,CAACU,QAAQK,KAAK,IAAI,IAAI,CAACR,MAAM,CAACQ,KAAK,CAAC;YAC9E,MAAM2C,aAAa,AAACF,KAAKG,IAAI,CAACC,YAAY,CAACC,YAAY,GAAG,OAAQ7D,QAAQC,eAAe;YACzF,MAAM6D,iBAAiB,AAACN,KAAKG,IAAI,CAACC,YAAY,CAACG,aAAa,GAAG,OAAQ/D,QAAQE,mBAAmB;YAElG,OAAO;gBACL8D,IAAIkB,WAAWlB,EAAE;gBACjBjD,OAAOL,QAAQK,KAAK,IAAI,IAAI,CAACR,MAAM,CAACQ,KAAK;gBACzCmD,UAAU;gBACVxC,SAASwD,WAAWf,IAAI;gBACxBC,OAAO;oBACLC,cAAcb,KAAKG,IAAI,CAACC,YAAY,CAACC,YAAY;oBACjDS,kBAAkBd,KAAKG,IAAI,CAACC,YAAY,CAACG,aAAa;oBACtDQ,aAAaf,KAAKG,IAAI,CAACC,YAAY,CAACC,YAAY,GAAGL,KAAKG,IAAI,CAACC,YAAY,CAACG,aAAa;gBACzF;gBACAS,MAAM;oBACJd;oBACAI;oBACAW,WAAWf,aAAaI;oBACxB3D,UAAU;gBACZ;gBACAuE,cAAc,IAAI,CAACC,eAAe,CAACO,WAAWN,aAAa;YAC7D;QACF,EAAE,OAAOC,OAAO;YACdxB,aAAaV;YACb,MAAM,IAAI,CAACmC,cAAc,CAACD;QAC5B;IACF;IAEA,OAAiBO,iBAAiB1E,OAAmB,EAAiC;QACpF,MAAMC,SAASD,QAAQE,QAAQ,CAACC,MAAM,GAAG,KAAKH,QAAQE,QAAQ,CAAC,EAAE,CAACE,IAAI,KAAK;QAC3E,MAAMC,QAAQL,QAAQK,KAAK,IAAI,IAAI,CAACR,MAAM,CAACQ,KAAK;QAEhD,IAAIJ,UAAUI,MAAMC,UAAU,CAAC,YAAY;YACzC,OAAO,IAAI,CAACqE,kBAAkB,CAAC3E;QACjC,OAAO;YACL,OAAO,IAAI,CAAC4E,sBAAsB,CAAC5E;QACrC;IACF;IAEA,OAAe2E,mBAAmB3E,OAAmB,EAAiC;QACpF,MAAME,WAAW,IAAI,CAACO,eAAe,CAACT,QAAQE,QAAQ;QACtD,MAAMQ,gBAAgBV,QAAQE,QAAQ,CAACS,IAAI,CAACC,CAAAA,IAAKA,EAAER,IAAI,KAAK;QAE5D,MAAMS,gBAAgB;YACpBR,OAAO,IAAI,CAACS,gBAAgB,CAACd,QAAQK,KAAK,IAAI,IAAI,CAACR,MAAM,CAACQ,KAAK;YAC/DH;YACAa,UAAUL,eAAeM;YACzBC,aAAajB,QAAQiB,WAAW,IAAI,IAAI,CAACpB,MAAM,CAACoB,WAAW;YAC3DC,YAAYlB,QAAQmB,SAAS,IAAI,IAAI,CAACtB,MAAM,CAACsB,SAAS;YACtDC,GAAGpB,QAAQqB,IAAI,IAAI,IAAI,CAACxB,MAAM,CAACwB,IAAI;YACnCC,GAAGtB,QAAQuB,IAAI,IAAI,IAAI,CAAC1B,MAAM,CAAC0B,IAAI;YACnCC,mBAAmBxB,QAAQyB,gBAAgB,IAAI,IAAI,CAAC5B,MAAM,CAAC4B,gBAAgB;YAC3EC,kBAAkB1B,QAAQ2B,eAAe,IAAI,IAAI,CAAC9B,MAAM,CAAC8B,eAAe;YACxEC,gBAAgB5B,QAAQ6B,aAAa,IAAI,IAAI,CAAChC,MAAM,CAACgC,aAAa;YAClEC,QAAQ;QACV;QAEA,MAAMC,aAAa,IAAIC;QACvB,MAAMC,UAAUC,WAAW,IAAMH,WAAWI,KAAK,IAAI,AAAC,CAAA,IAAI,CAACtC,MAAM,CAACoC,OAAO,IAAI,KAAI,IAAK;QAEtF,IAAI;YACF,MAAMG,WAAW,MAAMC,MAAM,GAAG,IAAI,CAAC3C,OAAO,CAAC,KAAK,CAAC,EAAE;gBACnD4C,QAAQ;gBACR3C,SAAS,IAAI,CAACA,OAAO;gBACrB4C,MAAMC,KAAKC,SAAS,CAAC5B;gBACrB6B,QAAQX,WAAWW,MAAM;YAC3B;YAEA,IAAI,CAACN,SAASQ,EAAE,EAAE;gBAChB,MAAM,IAAI,CAACC,mBAAmB,CAACT;YACjC;YAEA,MAAMyC,SAASzC,SAASG,IAAI,CAAEuC,SAAS;YACvC,MAAMC,UAAU,IAAIC;YACpB,IAAIC,SAAS;YACb,IAAIC,eAAe;YAEnB,MAAO,KAAM;gBACX,MAAM,EAAEC,IAAI,EAAEC,KAAK,EAAE,GAAG,MAAMP,OAAOQ,IAAI;gBACzC,IAAIF,MAAM;gBAEVF,UAAUF,QAAQO,MAAM,CAACF,OAAO;oBAAEtD,QAAQ;gBAAK;gBAC/C,MAAMyD,QAAQN,OAAOO,KAAK,CAAC;gBAC3BP,SAASM,MAAME,GAAG,MAAM;gBAExB,KAAK,MAAMC,QAAQH,MAAO;oBACxB,IAAIG,KAAKC,IAAI,OAAO,IAAI;oBAExB,IAAI;wBACF,MAAM7C,OAAON,KAAKoD,KAAK,CAACF;wBAExB,IAAI5C,KAAKW,IAAI,EAAE;4BACbyB,gBAAgBpC,KAAKW,IAAI;4BACzB,MAAM;gCACJoC,MAAM;gCACNC,OAAO;oCAAE9E,SAAS8B,KAAKW,IAAI;gCAAC;4BAC9B;wBACF;wBAEA,IAAIX,KAAKiD,WAAW,EAAE;4BAEpB,MAAMpC,eAAe,IAAI,CAACqC,cAAc,CAACxD,KAAKC,SAAS,CAACzC,QAAQE,QAAQ;4BACxE,MAAM0D,mBAAmB,IAAI,CAACoC,cAAc,CAACd;4BAE7C,MAAM5F,UAAU,IAAI,CAAClB,YAAY,CAACkB,OAAO,AAAC,CAACU,QAAQK,KAAK,IAAI,IAAI,CAACR,MAAM,CAACQ,KAAK,CAAC;4BAC9E,MAAM2C,aAAa,AAACW,eAAe,OAAQrE,QAAQC,eAAe;4BAClE,MAAM6D,iBAAiB,AAACQ,mBAAmB,OAAQtE,QAAQE,mBAAmB;4BAE9E,MAAM;gCACJqG,MAAM;gCACNnC,OAAO;oCACLC;oCACAC;oCACAC,aAAaF,eAAeC;gCAC9B;gCACAE,MAAM;oCACJd;oCACAI;oCACAW,WAAWf,aAAaI;oCACxB3D,UAAU;gCACZ;4BACF;wBACF;oBACF,EAAE,OAAOwG,GAAG;wBACV,IAAI,CAACC,MAAM,CAACC,IAAI,CAAC,uCAAuC;4BAAET;4BAAMvB,OAAO8B;wBAAE;oBAC3E;gBACF;YACF;QACF,EAAE,OAAO9B,OAAO;YACdxB,aAAaV;YACb,MAAM,IAAI,CAACmC,cAAc,CAACD;QAC5B,SAAU;YACRxB,aAAaV;QACf;IACF;IAEA,OAAe2C,uBAAuB5E,OAAmB,EAAiC;QAGxF,OAAO,IAAI,CAAC2E,kBAAkB,CAAC3E;IACjC;IAEA,MAAMoG,aAAkC;QACtC,OAAO,IAAI,CAAChI,YAAY,CAACC,eAAe;IAC1C;IAEA,MAAMgI,aAAahG,KAAe,EAAsB;QACtD,OAAO;YACLA;YACAlC,MAAMkC;YACNiG,aAAa,IAAI,CAACC,mBAAmB,CAAClG;YACtCmG,eAAe,IAAI,CAACpI,YAAY,CAACE,gBAAgB,CAAC+B,MAAM,IAAI;YAC5D9B,iBAAiB,IAAI,CAACH,YAAY,CAACG,eAAe,CAAC8B,MAAM,IAAI;YAC7DoG,mBAAmB;gBACjB;gBACA;gBACA;mBACIpG,MAAMC,UAAU,CAAC,aAAa;oBAAC;iBAAQ,GAAG,EAAE;aACjD;YACDhB,SAAS,IAAI,CAAClB,YAAY,CAACkB,OAAO,AAAC,CAACe,MAAM;QAC5C;IACF;IAEA,MAAgBqG,gBAA4C;QAC1D,IAAI;YACF,MAAMtE,WAAW,MAAMC,MAAM,GAAG,IAAI,CAAC3C,OAAO,CAAC,cAAc,CAAC,EAAE;gBAC5D4C,QAAQ;gBACR3C,SAAS,IAAI,CAACA,OAAO;YACvB;YAEA,IAAI,CAACyC,SAASQ,EAAE,EAAE;gBAChB,MAAM,IAAI+D,MAAM,CAAC,qBAAqB,EAAEvE,SAASwE,MAAM,EAAE;YAC3D;YAEA,OAAO;gBACLC,SAAS;gBACTC,WAAW,IAAIC;YACjB;QACF,EAAE,OAAO5C,OAAO;YACd,OAAO;gBACL0C,SAAS;gBACT1C,OAAOA,iBAAiBwC,QAAQxC,MAAM6C,OAAO,GAAG;gBAChDF,WAAW,IAAIC;YACjB;QACF;IACF;IAEQtG,gBAAgBP,QAAgC,EAAE;QACxD,OAAOA,SACJ+G,MAAM,CAACrG,CAAAA,IAAKA,EAAER,IAAI,KAAK,UACvBkE,GAAG,CAAC1D,CAAAA,IAAM,CAAA;gBACTR,MAAMQ,EAAER,IAAI,KAAK,cAAc,YAAqB;gBACpD4G,SAASpG,EAAEI,OAAO;YACpB,CAAA;IACJ;IAEQF,iBAAiBT,KAAe,EAAU;QAChD,MAAM6G,WAAmC;YACvC,WAAW;YACX,iBAAiB;YACjB,mBAAmB;YACnB,mBAAmB;YACnB,mBAAmB;QACrB;QACA,OAAOA,QAAQ,CAAC7G,MAAM,IAAIA;IAC5B;IAEQ4D,gBAAgBkD,MAAc,EAAqB;QACzD,OAAOA,WAAW,aAAa,SAAS;IAC1C;IAEQZ,oBAAoBlG,KAAe,EAAU;QACnD,MAAM+G,eAAuC;YAC3C,WAAW;YACX,iBAAiB;YACjB,mBAAmB;YACnB,mBAAmB;YACnB,mBAAmB;QACrB;QACA,OAAOA,YAAY,CAAC/G,MAAM,IAAI;IAChC;IAEA,MAAcwC,oBAAoBT,QAAkB,EAAiB;QACnE,MAAMiF,YAAY,MAAMjF,SAASqB,IAAI;QACrC,IAAI6D;QAEJ,IAAI;YACFA,YAAY9E,KAAKoD,KAAK,CAACyB;QACzB,EAAE,OAAM;YACNC,YAAY;gBAAEN,SAASK;YAAU;QACnC;QAEA,MAAML,UAAUM,UAAUN,OAAO,IAAI;QAErC,OAAQ5E,SAASwE,MAAM;YACrB,KAAK;gBACH,MAAM,IAAI3I,oBAAoB+I,SAAS,UAAUM;YACnD,KAAK;gBACH,MAAM,IAAItJ,eAAegJ,SAAS,UAAUO,WAAWD;YACzD;gBACE,MAAM,IAAIvJ,iBACRiJ,SACA,CAAC,OAAO,EAAE5E,SAASwE,MAAM,EAAE,EAC3B,UACAxE,SAASwE,MAAM,EACfxE,SAASwE,MAAM,IAAI,KACnBU;QAEN;IACF;AACF"}