{
  "version": 3,
  "sources": ["../../src/providers/cohere-provider.ts"],
  "sourcesContent": ["/**\n * Cohere Provider Implementation\n * Supports Command, Generate, and other Cohere models\n */\n\nimport { BaseProvider } from './base-provider.js';\nimport {\n  LLMProvider,\n  LLMModel,\n  LLMRequest,\n  LLMResponse,\n  LLMStreamEvent,\n  ModelInfo,\n  ProviderCapabilities,\n  HealthCheckResult,\n  LLMProviderError,\n  RateLimitError,\n  AuthenticationError,\n} from './types.js';\n\ninterface CohereGenerateRequest {\n  model: string;\n  prompt?: string;\n  messages?: Array<{\n    role: 'USER' | 'CHATBOT' | 'SYSTEM';\n    message: string;\n  }>;\n  preamble?: string;\n  temperature?: number;\n  max_tokens?: number;\n  k?: number;\n  p?: number;\n  frequency_penalty?: number;\n  presence_penalty?: number;\n  stop_sequences?: string[];\n  stream?: boolean;\n}\n\ninterface CohereGenerateResponse {\n  id: string;\n  generations: Array<{\n    id: string;\n    text: string;\n    finish_reason: string;\n  }>;\n  prompt: string;\n  meta: {\n    api_version: {\n      version: string;\n    };\n    billed_units: {\n      input_tokens: number;\n      output_tokens: number;\n    };\n  };\n}\n\ninterface CohereChatResponse {\n  text: string;\n  generation_id: string;\n  finish_reason: string;\n  meta: {\n    api_version: {\n      version: string;\n    };\n    billed_units: {\n      input_tokens: number;\n      output_tokens: number;\n    };\n  };\n}\n\nexport class CohereProvider extends BaseProvider {\n  readonly name: LLMProvider = 'cohere';\n  readonly capabilities: ProviderCapabilities = {\n    supportedModels: [\n      'command',\n      'command-light',\n      'command-nightly',\n      'generate-xlarge',\n      'generate-medium',\n    ],\n    maxContextLength: {\n      'command': 4096,\n      'command-light': 4096,\n      'command-nightly': 8192,\n      'generate-xlarge': 2048,\n      'generate-medium': 2048,\n    } as Record<LLMModel, number>,\n    maxOutputTokens: {\n      'command': 4096,\n      'command-light': 4096,\n      'command-nightly': 4096,\n      'generate-xlarge': 2048,\n      'generate-medium': 2048,\n    } as Record<LLMModel, number>,\n    supportsStreaming: true,\n    supportsFunctionCalling: false,\n    supportsSystemMessages: true,\n    supportsVision: false,\n    supportsAudio: false,\n    supportsTools: true,\n    supportsFineTuning: true,\n    supportsEmbeddings: true,\n    supportsLogprobs: true,\n    supportsBatching: false,\n    rateLimit: {\n      requestsPerMinute: 100,\n      tokensPerMinute: 100000,\n      concurrentRequests: 20,\n    },\n    pricing: {\n      'command': {\n        promptCostPer1k: 0.0015,\n        completionCostPer1k: 0.0015,\n        currency: 'USD',\n      },\n      'command-light': {\n        promptCostPer1k: 0.00015,\n        completionCostPer1k: 0.00015,\n        currency: 'USD',\n      },\n      'command-nightly': {\n        promptCostPer1k: 0.0015,\n        completionCostPer1k: 0.0015,\n        currency: 'USD',\n      },\n      'generate-xlarge': {\n        promptCostPer1k: 0.005,\n        completionCostPer1k: 0.015,\n        currency: 'USD',\n      },\n      'generate-medium': {\n        promptCostPer1k: 0.001,\n        completionCostPer1k: 0.005,\n        currency: 'USD',\n      },\n    },\n  };\n\n  private baseUrl = 'https://api.cohere.ai/v1';\n  private headers: Record<string, string> = {};\n\n  protected async doInitialize(): Promise<void> {\n    if (!this.config.apiKey) {\n      throw new AuthenticationError('Cohere API key is required', 'cohere');\n    }\n\n    this.headers = {\n      'Authorization': `Bearer ${this.config.apiKey}`,\n      'Content-Type': 'application/json',\n      'Accept': 'application/json',\n    };\n  }\n\n  protected async doComplete(request: LLMRequest): Promise<LLMResponse> {\n    const isChat = request.messages.length > 1 || request.messages[0].role !== 'user';\n    const model = request.model || this.config.model;\n    \n    if (isChat && model.startsWith('command')) {\n      return this.doChatComplete(request);\n    } else {\n      return this.doGenerateComplete(request);\n    }\n  }\n\n  private async doChatComplete(request: LLMRequest): Promise<LLMResponse> {\n    const messages = this.convertMessages(request.messages);\n    const systemMessage = request.messages.find(m => m.role === 'system');\n    \n    const cohereRequest = {\n      model: this.mapToCohereModel(request.model || this.config.model),\n      messages,\n      preamble: systemMessage?.content,\n      temperature: request.temperature ?? this.config.temperature,\n      max_tokens: request.maxTokens ?? this.config.maxTokens,\n      k: request.topK ?? this.config.topK,\n      p: request.topP ?? this.config.topP,\n      frequency_penalty: request.frequencyPenalty ?? this.config.frequencyPenalty,\n      presence_penalty: request.presencePenalty ?? this.config.presencePenalty,\n      stop_sequences: request.stopSequences ?? this.config.stopSequences,\n      stream: false,\n    };\n\n    const controller = new AbortController();\n    const timeout = setTimeout(() => controller.abort(), this.config.timeout || 60000);\n\n    try {\n      const response = await fetch(`${this.baseUrl}/chat`, {\n        method: 'POST',\n        headers: this.headers,\n        body: JSON.stringify(cohereRequest),\n        signal: controller.signal,\n      });\n\n      clearTimeout(timeout);\n\n      if (!response.ok) {\n        await this.handleErrorResponse(response);\n      }\n\n      const data: CohereChatResponse = await response.json();\n      \n      // Calculate cost\n      const pricing = this.capabilities.pricing![request.model || this.config.model];\n      const promptCost = (data.meta.billed_units.input_tokens / 1000) * pricing.promptCostPer1k;\n      const completionCost = (data.meta.billed_units.output_tokens / 1000) * pricing.completionCostPer1k;\n\n      return {\n        id: data.generation_id,\n        model: request.model || this.config.model,\n        provider: 'cohere',\n        content: data.text,\n        usage: {\n          promptTokens: data.meta.billed_units.input_tokens,\n          completionTokens: data.meta.billed_units.output_tokens,\n          totalTokens: data.meta.billed_units.input_tokens + data.meta.billed_units.output_tokens,\n        },\n        cost: {\n          promptCost,\n          completionCost,\n          totalCost: promptCost + completionCost,\n          currency: 'USD',\n        },\n        finishReason: this.mapFinishReason(data.finish_reason),\n      };\n    } catch (error) {\n      clearTimeout(timeout);\n      throw this.transformError(error);\n    }\n  }\n\n  private async doGenerateComplete(request: LLMRequest): Promise<LLMResponse> {\n    // For generate endpoint, concatenate messages into a prompt\n    const prompt = request.messages.map(m => m.content).join('\\n\\n');\n    \n    const cohereRequest: CohereGenerateRequest = {\n      model: this.mapToCohereModel(request.model || this.config.model),\n      prompt,\n      temperature: request.temperature ?? this.config.temperature,\n      max_tokens: request.maxTokens ?? this.config.maxTokens,\n      k: request.topK ?? this.config.topK,\n      p: request.topP ?? this.config.topP,\n      frequency_penalty: request.frequencyPenalty ?? this.config.frequencyPenalty,\n      presence_penalty: request.presencePenalty ?? this.config.presencePenalty,\n      stop_sequences: request.stopSequences ?? this.config.stopSequences,\n      stream: false,\n    };\n\n    const controller = new AbortController();\n    const timeout = setTimeout(() => controller.abort(), this.config.timeout || 60000);\n\n    try {\n      const response = await fetch(`${this.baseUrl}/generate`, {\n        method: 'POST',\n        headers: this.headers,\n        body: JSON.stringify(cohereRequest),\n        signal: controller.signal,\n      });\n\n      clearTimeout(timeout);\n\n      if (!response.ok) {\n        await this.handleErrorResponse(response);\n      }\n\n      const data: CohereGenerateResponse = await response.json();\n      const generation = data.generations[0];\n      \n      // Calculate cost\n      const pricing = this.capabilities.pricing![request.model || this.config.model];\n      const promptCost = (data.meta.billed_units.input_tokens / 1000) * pricing.promptCostPer1k;\n      const completionCost = (data.meta.billed_units.output_tokens / 1000) * pricing.completionCostPer1k;\n\n      return {\n        id: generation.id,\n        model: request.model || this.config.model,\n        provider: 'cohere',\n        content: generation.text,\n        usage: {\n          promptTokens: data.meta.billed_units.input_tokens,\n          completionTokens: data.meta.billed_units.output_tokens,\n          totalTokens: data.meta.billed_units.input_tokens + data.meta.billed_units.output_tokens,\n        },\n        cost: {\n          promptCost,\n          completionCost,\n          totalCost: promptCost + completionCost,\n          currency: 'USD',\n        },\n        finishReason: this.mapFinishReason(generation.finish_reason),\n      };\n    } catch (error) {\n      clearTimeout(timeout);\n      throw this.transformError(error);\n    }\n  }\n\n  protected async *doStreamComplete(request: LLMRequest): AsyncIterable<LLMStreamEvent> {\n    const isChat = request.messages.length > 1 || request.messages[0].role !== 'user';\n    const model = request.model || this.config.model;\n    \n    if (isChat && model.startsWith('command')) {\n      yield* this.streamChatComplete(request);\n    } else {\n      yield* this.streamGenerateComplete(request);\n    }\n  }\n\n  private async *streamChatComplete(request: LLMRequest): AsyncIterable<LLMStreamEvent> {\n    const messages = this.convertMessages(request.messages);\n    const systemMessage = request.messages.find(m => m.role === 'system');\n    \n    const cohereRequest = {\n      model: this.mapToCohereModel(request.model || this.config.model),\n      messages,\n      preamble: systemMessage?.content,\n      temperature: request.temperature ?? this.config.temperature,\n      max_tokens: request.maxTokens ?? this.config.maxTokens,\n      k: request.topK ?? this.config.topK,\n      p: request.topP ?? this.config.topP,\n      frequency_penalty: request.frequencyPenalty ?? this.config.frequencyPenalty,\n      presence_penalty: request.presencePenalty ?? this.config.presencePenalty,\n      stop_sequences: request.stopSequences ?? this.config.stopSequences,\n      stream: true,\n    };\n\n    const controller = new AbortController();\n    const timeout = setTimeout(() => controller.abort(), (this.config.timeout || 60000) * 2);\n\n    try {\n      const response = await fetch(`${this.baseUrl}/chat`, {\n        method: 'POST',\n        headers: this.headers,\n        body: JSON.stringify(cohereRequest),\n        signal: controller.signal,\n      });\n\n      if (!response.ok) {\n        await this.handleErrorResponse(response);\n      }\n\n      const reader = response.body!.getReader();\n      const decoder = new TextDecoder();\n      let buffer = '';\n      let totalContent = '';\n\n      while (true) {\n        const { done, value } = await reader.read();\n        if (done) break;\n\n        buffer += decoder.decode(value, { stream: true });\n        const lines = buffer.split('\\n');\n        buffer = lines.pop() || '';\n\n        for (const line of lines) {\n          if (line.trim() === '') continue;\n          \n          try {\n            const data = JSON.parse(line);\n            \n            if (data.text) {\n              totalContent += data.text;\n              yield {\n                type: 'content',\n                delta: { content: data.text },\n              };\n            }\n            \n            if (data.is_finished) {\n              // Estimate tokens for streaming\n              const promptTokens = this.estimateTokens(JSON.stringify(request.messages));\n              const completionTokens = this.estimateTokens(totalContent);\n              \n              const pricing = this.capabilities.pricing![request.model || this.config.model];\n              const promptCost = (promptTokens / 1000) * pricing.promptCostPer1k;\n              const completionCost = (completionTokens / 1000) * pricing.completionCostPer1k;\n\n              yield {\n                type: 'done',\n                usage: {\n                  promptTokens,\n                  completionTokens,\n                  totalTokens: promptTokens + completionTokens,\n                },\n                cost: {\n                  promptCost,\n                  completionCost,\n                  totalCost: promptCost + completionCost,\n                  currency: 'USD',\n                },\n              };\n            }\n          } catch (e) {\n            this.logger.warn('Failed to parse Cohere stream chunk', { line, error: e });\n          }\n        }\n      }\n    } catch (error) {\n      clearTimeout(timeout);\n      throw this.transformError(error);\n    } finally {\n      clearTimeout(timeout);\n    }\n  }\n\n  private async *streamGenerateComplete(request: LLMRequest): AsyncIterable<LLMStreamEvent> {\n    // Similar implementation for generate endpoint\n    // Omitted for brevity - follows same pattern as streamChatComplete\n    yield* this.streamChatComplete(request); // Fallback to chat for now\n  }\n\n  async listModels(): Promise<LLMModel[]> {\n    return this.capabilities.supportedModels;\n  }\n\n  async getModelInfo(model: LLMModel): Promise<ModelInfo> {\n    return {\n      model,\n      name: model,\n      description: this.getModelDescription(model),\n      contextLength: this.capabilities.maxContextLength[model] || 4096,\n      maxOutputTokens: this.capabilities.maxOutputTokens[model] || 4096,\n      supportedFeatures: [\n        'chat',\n        'completion',\n        'embeddings',\n        ...(model.startsWith('command') ? ['tools'] : []),\n      ],\n      pricing: this.capabilities.pricing![model],\n    };\n  }\n\n  protected async doHealthCheck(): Promise<HealthCheckResult> {\n    try {\n      const response = await fetch(`${this.baseUrl}/check-api-key`, {\n        method: 'POST',\n        headers: this.headers,\n      });\n\n      if (!response.ok) {\n        throw new Error(`Health check failed: ${response.status}`);\n      }\n\n      return {\n        healthy: true,\n        timestamp: new Date(),\n      };\n    } catch (error) {\n      return {\n        healthy: false,\n        error: error instanceof Error ? error.message : 'Unknown error',\n        timestamp: new Date(),\n      };\n    }\n  }\n\n  private convertMessages(messages: LLMRequest['messages']) {\n    return messages\n      .filter(m => m.role !== 'system')\n      .map(m => ({\n        role: m.role === 'assistant' ? 'CHATBOT' as const : 'USER' as const,\n        message: m.content,\n      }));\n  }\n\n  private mapToCohereModel(model: LLMModel): string {\n    const modelMap: Record<string, string> = {\n      'command': 'command',\n      'command-light': 'command-light',\n      'command-nightly': 'command-nightly',\n      'generate-xlarge': 'xlarge',\n      'generate-medium': 'medium',\n    };\n    return modelMap[model] || model;\n  }\n\n  private mapFinishReason(reason: string): 'stop' | 'length' {\n    return reason === 'COMPLETE' ? 'stop' : 'length';\n  }\n\n  private getModelDescription(model: LLMModel): string {\n    const descriptions: Record<string, string> = {\n      'command': 'Powerful model for complex tasks',\n      'command-light': 'Faster, lightweight version of Command',\n      'command-nightly': 'Latest experimental Command model',\n      'generate-xlarge': 'Large generation model',\n      'generate-medium': 'Medium generation model',\n    };\n    return descriptions[model] || 'Cohere language model';\n  }\n\n  private async handleErrorResponse(response: Response): Promise<void> {\n    const errorText = await response.text();\n    let errorData: any;\n\n    try {\n      errorData = JSON.parse(errorText);\n    } catch {\n      errorData = { message: errorText };\n    }\n\n    const message = errorData.message || 'Unknown error';\n\n    switch (response.status) {\n      case 401:\n        throw new AuthenticationError(message, 'cohere', errorData);\n      case 429:\n        throw new RateLimitError(message, 'cohere', undefined, errorData);\n      default:\n        throw new LLMProviderError(\n          message,\n          `COHERE_${response.status}`,\n          'cohere',\n          response.status,\n          response.status >= 500,\n          errorData\n        );\n    }\n  }\n}"],
  "mappings": ";;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA,2BAA6B;AAC7B,mBAYO;AAsDA,MAAM,uBAAuB,kCAAa;AAAA,EAxEjD,OAwEiD;AAAA;AAAA;AAAA,EACtC,OAAoB;AAAA,EACpB,eAAqC;AAAA,IAC5C,iBAAiB;AAAA,MACf;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAAA,IACA,kBAAkB;AAAA,MAChB,WAAW;AAAA,MACX,iBAAiB;AAAA,MACjB,mBAAmB;AAAA,MACnB,mBAAmB;AAAA,MACnB,mBAAmB;AAAA,IACrB;AAAA,IACA,iBAAiB;AAAA,MACf,WAAW;AAAA,MACX,iBAAiB;AAAA,MACjB,mBAAmB;AAAA,MACnB,mBAAmB;AAAA,MACnB,mBAAmB;AAAA,IACrB;AAAA,IACA,mBAAmB;AAAA,IACnB,yBAAyB;AAAA,IACzB,wBAAwB;AAAA,IACxB,gBAAgB;AAAA,IAChB,eAAe;AAAA,IACf,eAAe;AAAA,IACf,oBAAoB;AAAA,IACpB,oBAAoB;AAAA,IACpB,kBAAkB;AAAA,IAClB,kBAAkB;AAAA,IAClB,WAAW;AAAA,MACT,mBAAmB;AAAA,MACnB,iBAAiB;AAAA,MACjB,oBAAoB;AAAA,IACtB;AAAA,IACA,SAAS;AAAA,MACP,WAAW;AAAA,QACT,iBAAiB;AAAA,QACjB,qBAAqB;AAAA,QACrB,UAAU;AAAA,MACZ;AAAA,MACA,iBAAiB;AAAA,QACf,iBAAiB;AAAA,QACjB,qBAAqB;AAAA,QACrB,UAAU;AAAA,MACZ;AAAA,MACA,mBAAmB;AAAA,QACjB,iBAAiB;AAAA,QACjB,qBAAqB;AAAA,QACrB,UAAU;AAAA,MACZ;AAAA,MACA,mBAAmB;AAAA,QACjB,iBAAiB;AAAA,QACjB,qBAAqB;AAAA,QACrB,UAAU;AAAA,MACZ;AAAA,MACA,mBAAmB;AAAA,QACjB,iBAAiB;AAAA,QACjB,qBAAqB;AAAA,QACrB,UAAU;AAAA,MACZ;AAAA,IACF;AAAA,EACF;AAAA,EAEQ,UAAU;AAAA,EACV,UAAkC,CAAC;AAAA,EAE3C,MAAgB,eAA8B;AAC5C,QAAI,CAAC,KAAK,OAAO,QAAQ;AACvB,YAAM,IAAI,iCAAoB,8BAA8B,QAAQ;AAAA,IACtE;AAEA,SAAK,UAAU;AAAA,MACb,iBAAiB,UAAU,KAAK,OAAO,MAAM;AAAA,MAC7C,gBAAgB;AAAA,MAChB,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,MAAgB,WAAW,SAA2C;AACpE,UAAM,SAAS,QAAQ,SAAS,SAAS,KAAK,QAAQ,SAAS,CAAC,EAAE,SAAS;AAC3E,UAAM,QAAQ,QAAQ,SAAS,KAAK,OAAO;AAE3C,QAAI,UAAU,MAAM,WAAW,SAAS,GAAG;AACzC,aAAO,KAAK,eAAe,OAAO;AAAA,IACpC,OAAO;AACL,aAAO,KAAK,mBAAmB,OAAO;AAAA,IACxC;AAAA,EACF;AAAA,EAEA,MAAc,eAAe,SAA2C;AACtE,UAAM,WAAW,KAAK,gBAAgB,QAAQ,QAAQ;AACtD,UAAM,gBAAgB,QAAQ,SAAS,KAAK,OAAK,EAAE,SAAS,QAAQ;AAEpE,UAAM,gBAAgB;AAAA,MACpB,OAAO,KAAK,iBAAiB,QAAQ,SAAS,KAAK,OAAO,KAAK;AAAA,MAC/D;AAAA,MACA,UAAU,eAAe;AAAA,MACzB,aAAa,QAAQ,eAAe,KAAK,OAAO;AAAA,MAChD,YAAY,QAAQ,aAAa,KAAK,OAAO;AAAA,MAC7C,GAAG,QAAQ,QAAQ,KAAK,OAAO;AAAA,MAC/B,GAAG,QAAQ,QAAQ,KAAK,OAAO;AAAA,MAC/B,mBAAmB,QAAQ,oBAAoB,KAAK,OAAO;AAAA,MAC3D,kBAAkB,QAAQ,mBAAmB,KAAK,OAAO;AAAA,MACzD,gBAAgB,QAAQ,iBAAiB,KAAK,OAAO;AAAA,MACrD,QAAQ;AAAA,IACV;AAEA,UAAM,aAAa,IAAI,gBAAgB;AACvC,UAAM,UAAU,WAAW,MAAM,WAAW,MAAM,GAAG,KAAK,OAAO,WAAW,GAAK;AAEjF,QAAI;AACF,YAAM,WAAW,MAAM,MAAM,GAAG,KAAK,OAAO,SAAS;AAAA,QACnD,QAAQ;AAAA,QACR,SAAS,KAAK;AAAA,QACd,MAAM,KAAK,UAAU,aAAa;AAAA,QAClC,QAAQ,WAAW;AAAA,MACrB,CAAC;AAED,mBAAa,OAAO;AAEpB,UAAI,CAAC,SAAS,IAAI;AAChB,cAAM,KAAK,oBAAoB,QAAQ;AAAA,MACzC;AAEA,YAAM,OAA2B,MAAM,SAAS,KAAK;AAGrD,YAAM,UAAU,KAAK,aAAa,QAAS,QAAQ,SAAS,KAAK,OAAO,KAAK;AAC7E,YAAM,aAAc,KAAK,KAAK,aAAa,eAAe,MAAQ,QAAQ;AAC1E,YAAM,iBAAkB,KAAK,KAAK,aAAa,gBAAgB,MAAQ,QAAQ;AAE/E,aAAO;AAAA,QACL,IAAI,KAAK;AAAA,QACT,OAAO,QAAQ,SAAS,KAAK,OAAO;AAAA,QACpC,UAAU;AAAA,QACV,SAAS,KAAK;AAAA,QACd,OAAO;AAAA,UACL,cAAc,KAAK,KAAK,aAAa;AAAA,UACrC,kBAAkB,KAAK,KAAK,aAAa;AAAA,UACzC,aAAa,KAAK,KAAK,aAAa,eAAe,KAAK,KAAK,aAAa;AAAA,QAC5E;AAAA,QACA,MAAM;AAAA,UACJ;AAAA,UACA;AAAA,UACA,WAAW,aAAa;AAAA,UACxB,UAAU;AAAA,QACZ;AAAA,QACA,cAAc,KAAK,gBAAgB,KAAK,aAAa;AAAA,MACvD;AAAA,IACF,SAAS,OAAO;AACd,mBAAa,OAAO;AACpB,YAAM,KAAK,eAAe,KAAK;AAAA,IACjC;AAAA,EACF;AAAA,EAEA,MAAc,mBAAmB,SAA2C;AAE1E,UAAM,SAAS,QAAQ,SAAS,IAAI,OAAK,EAAE,OAAO,EAAE,KAAK,MAAM;AAE/D,UAAM,gBAAuC;AAAA,MAC3C,OAAO,KAAK,iBAAiB,QAAQ,SAAS,KAAK,OAAO,KAAK;AAAA,MAC/D;AAAA,MACA,aAAa,QAAQ,eAAe,KAAK,OAAO;AAAA,MAChD,YAAY,QAAQ,aAAa,KAAK,OAAO;AAAA,MAC7C,GAAG,QAAQ,QAAQ,KAAK,OAAO;AAAA,MAC/B,GAAG,QAAQ,QAAQ,KAAK,OAAO;AAAA,MAC/B,mBAAmB,QAAQ,oBAAoB,KAAK,OAAO;AAAA,MAC3D,kBAAkB,QAAQ,mBAAmB,KAAK,OAAO;AAAA,MACzD,gBAAgB,QAAQ,iBAAiB,KAAK,OAAO;AAAA,MACrD,QAAQ;AAAA,IACV;AAEA,UAAM,aAAa,IAAI,gBAAgB;AACvC,UAAM,UAAU,WAAW,MAAM,WAAW,MAAM,GAAG,KAAK,OAAO,WAAW,GAAK;AAEjF,QAAI;AACF,YAAM,WAAW,MAAM,MAAM,GAAG,KAAK,OAAO,aAAa;AAAA,QACvD,QAAQ;AAAA,QACR,SAAS,KAAK;AAAA,QACd,MAAM,KAAK,UAAU,aAAa;AAAA,QAClC,QAAQ,WAAW;AAAA,MACrB,CAAC;AAED,mBAAa,OAAO;AAEpB,UAAI,CAAC,SAAS,IAAI;AAChB,cAAM,KAAK,oBAAoB,QAAQ;AAAA,MACzC;AAEA,YAAM,OAA+B,MAAM,SAAS,KAAK;AACzD,YAAM,aAAa,KAAK,YAAY,CAAC;AAGrC,YAAM,UAAU,KAAK,aAAa,QAAS,QAAQ,SAAS,KAAK,OAAO,KAAK;AAC7E,YAAM,aAAc,KAAK,KAAK,aAAa,eAAe,MAAQ,QAAQ;AAC1E,YAAM,iBAAkB,KAAK,KAAK,aAAa,gBAAgB,MAAQ,QAAQ;AAE/E,aAAO;AAAA,QACL,IAAI,WAAW;AAAA,QACf,OAAO,QAAQ,SAAS,KAAK,OAAO;AAAA,QACpC,UAAU;AAAA,QACV,SAAS,WAAW;AAAA,QACpB,OAAO;AAAA,UACL,cAAc,KAAK,KAAK,aAAa;AAAA,UACrC,kBAAkB,KAAK,KAAK,aAAa;AAAA,UACzC,aAAa,KAAK,KAAK,aAAa,eAAe,KAAK,KAAK,aAAa;AAAA,QAC5E;AAAA,QACA,MAAM;AAAA,UACJ;AAAA,UACA;AAAA,UACA,WAAW,aAAa;AAAA,UACxB,UAAU;AAAA,QACZ;AAAA,QACA,cAAc,KAAK,gBAAgB,WAAW,aAAa;AAAA,MAC7D;AAAA,IACF,SAAS,OAAO;AACd,mBAAa,OAAO;AACpB,YAAM,KAAK,eAAe,KAAK;AAAA,IACjC;AAAA,EACF;AAAA,EAEA,OAAiB,iBAAiB,SAAoD;AACpF,UAAM,SAAS,QAAQ,SAAS,SAAS,KAAK,QAAQ,SAAS,CAAC,EAAE,SAAS;AAC3E,UAAM,QAAQ,QAAQ,SAAS,KAAK,OAAO;AAE3C,QAAI,UAAU,MAAM,WAAW,SAAS,GAAG;AACzC,aAAO,KAAK,mBAAmB,OAAO;AAAA,IACxC,OAAO;AACL,aAAO,KAAK,uBAAuB,OAAO;AAAA,IAC5C;AAAA,EACF;AAAA,EAEA,OAAe,mBAAmB,SAAoD;AACpF,UAAM,WAAW,KAAK,gBAAgB,QAAQ,QAAQ;AACtD,UAAM,gBAAgB,QAAQ,SAAS,KAAK,OAAK,EAAE,SAAS,QAAQ;AAEpE,UAAM,gBAAgB;AAAA,MACpB,OAAO,KAAK,iBAAiB,QAAQ,SAAS,KAAK,OAAO,KAAK;AAAA,MAC/D;AAAA,MACA,UAAU,eAAe;AAAA,MACzB,aAAa,QAAQ,eAAe,KAAK,OAAO;AAAA,MAChD,YAAY,QAAQ,aAAa,KAAK,OAAO;AAAA,MAC7C,GAAG,QAAQ,QAAQ,KAAK,OAAO;AAAA,MAC/B,GAAG,QAAQ,QAAQ,KAAK,OAAO;AAAA,MAC/B,mBAAmB,QAAQ,oBAAoB,KAAK,OAAO;AAAA,MAC3D,kBAAkB,QAAQ,mBAAmB,KAAK,OAAO;AAAA,MACzD,gBAAgB,QAAQ,iBAAiB,KAAK,OAAO;AAAA,MACrD,QAAQ;AAAA,IACV;AAEA,UAAM,aAAa,IAAI,gBAAgB;AACvC,UAAM,UAAU,WAAW,MAAM,WAAW,MAAM,IAAI,KAAK,OAAO,WAAW,OAAS,CAAC;AAEvF,QAAI;AACF,YAAM,WAAW,MAAM,MAAM,GAAG,KAAK,OAAO,SAAS;AAAA,QACnD,QAAQ;AAAA,QACR,SAAS,KAAK;AAAA,QACd,MAAM,KAAK,UAAU,aAAa;AAAA,QAClC,QAAQ,WAAW;AAAA,MACrB,CAAC;AAED,UAAI,CAAC,SAAS,IAAI;AAChB,cAAM,KAAK,oBAAoB,QAAQ;AAAA,MACzC;AAEA,YAAM,SAAS,SAAS,KAAM,UAAU;AACxC,YAAM,UAAU,IAAI,YAAY;AAChC,UAAI,SAAS;AACb,UAAI,eAAe;AAEnB,aAAO,MAAM;AACX,cAAM,EAAE,MAAM,MAAM,IAAI,MAAM,OAAO,KAAK;AAC1C,YAAI;AAAM;AAEV,kBAAU,QAAQ,OAAO,OAAO,EAAE,QAAQ,KAAK,CAAC;AAChD,cAAM,QAAQ,OAAO,MAAM,IAAI;AAC/B,iBAAS,MAAM,IAAI,KAAK;AAExB,mBAAW,QAAQ,OAAO;AACxB,cAAI,KAAK,KAAK,MAAM;AAAI;AAExB,cAAI;AACF,kBAAM,OAAO,KAAK,MAAM,IAAI;AAE5B,gBAAI,KAAK,MAAM;AACb,8BAAgB,KAAK;AACrB,oBAAM;AAAA,gBACJ,MAAM;AAAA,gBACN,OAAO,EAAE,SAAS,KAAK,KAAK;AAAA,cAC9B;AAAA,YACF;AAEA,gBAAI,KAAK,aAAa;AAEpB,oBAAM,eAAe,KAAK,eAAe,KAAK,UAAU,QAAQ,QAAQ,CAAC;AACzE,oBAAM,mBAAmB,KAAK,eAAe,YAAY;AAEzD,oBAAM,UAAU,KAAK,aAAa,QAAS,QAAQ,SAAS,KAAK,OAAO,KAAK;AAC7E,oBAAM,aAAc,eAAe,MAAQ,QAAQ;AACnD,oBAAM,iBAAkB,mBAAmB,MAAQ,QAAQ;AAE3D,oBAAM;AAAA,gBACJ,MAAM;AAAA,gBACN,OAAO;AAAA,kBACL;AAAA,kBACA;AAAA,kBACA,aAAa,eAAe;AAAA,gBAC9B;AAAA,gBACA,MAAM;AAAA,kBACJ;AAAA,kBACA;AAAA,kBACA,WAAW,aAAa;AAAA,kBACxB,UAAU;AAAA,gBACZ;AAAA,cACF;AAAA,YACF;AAAA,UACF,SAAS,GAAG;AACV,iBAAK,OAAO,KAAK,uCAAuC,EAAE,MAAM,OAAO,EAAE,CAAC;AAAA,UAC5E;AAAA,QACF;AAAA,MACF;AAAA,IACF,SAAS,OAAO;AACd,mBAAa,OAAO;AACpB,YAAM,KAAK,eAAe,KAAK;AAAA,IACjC,UAAE;AACA,mBAAa,OAAO;AAAA,IACtB;AAAA,EACF;AAAA,EAEA,OAAe,uBAAuB,SAAoD;AAGxF,WAAO,KAAK,mBAAmB,OAAO;AAAA,EACxC;AAAA,EAEA,MAAM,aAAkC;AACtC,WAAO,KAAK,aAAa;AAAA,EAC3B;AAAA,EAEA,MAAM,aAAa,OAAqC;AACtD,WAAO;AAAA,MACL;AAAA,MACA,MAAM;AAAA,MACN,aAAa,KAAK,oBAAoB,KAAK;AAAA,MAC3C,eAAe,KAAK,aAAa,iBAAiB,KAAK,KAAK;AAAA,MAC5D,iBAAiB,KAAK,aAAa,gBAAgB,KAAK,KAAK;AAAA,MAC7D,mBAAmB;AAAA,QACjB;AAAA,QACA;AAAA,QACA;AAAA,QACA,GAAI,MAAM,WAAW,SAAS,IAAI,CAAC,OAAO,IAAI,CAAC;AAAA,MACjD;AAAA,MACA,SAAS,KAAK,aAAa,QAAS,KAAK;AAAA,IAC3C;AAAA,EACF;AAAA,EAEA,MAAgB,gBAA4C;AAC1D,QAAI;AACF,YAAM,WAAW,MAAM,MAAM,GAAG,KAAK,OAAO,kBAAkB;AAAA,QAC5D,QAAQ;AAAA,QACR,SAAS,KAAK;AAAA,MAChB,CAAC;AAED,UAAI,CAAC,SAAS,IAAI;AAChB,cAAM,IAAI,MAAM,wBAAwB,SAAS,MAAM,EAAE;AAAA,MAC3D;AAEA,aAAO;AAAA,QACL,SAAS;AAAA,QACT,WAAW,oBAAI,KAAK;AAAA,MACtB;AAAA,IACF,SAAS,OAAO;AACd,aAAO;AAAA,QACL,SAAS;AAAA,QACT,OAAO,iBAAiB,QAAQ,MAAM,UAAU;AAAA,QAChD,WAAW,oBAAI,KAAK;AAAA,MACtB;AAAA,IACF;AAAA,EACF;AAAA,EAEQ,gBAAgB,UAAkC;AACxD,WAAO,SACJ,OAAO,OAAK,EAAE,SAAS,QAAQ,EAC/B,IAAI,QAAM;AAAA,MACT,MAAM,EAAE,SAAS,cAAc,YAAqB;AAAA,MACpD,SAAS,EAAE;AAAA,IACb,EAAE;AAAA,EACN;AAAA,EAEQ,iBAAiB,OAAyB;AAChD,UAAM,WAAmC;AAAA,MACvC,WAAW;AAAA,MACX,iBAAiB;AAAA,MACjB,mBAAmB;AAAA,MACnB,mBAAmB;AAAA,MACnB,mBAAmB;AAAA,IACrB;AACA,WAAO,SAAS,KAAK,KAAK;AAAA,EAC5B;AAAA,EAEQ,gBAAgB,QAAmC;AACzD,WAAO,WAAW,aAAa,SAAS;AAAA,EAC1C;AAAA,EAEQ,oBAAoB,OAAyB;AACnD,UAAM,eAAuC;AAAA,MAC3C,WAAW;AAAA,MACX,iBAAiB;AAAA,MACjB,mBAAmB;AAAA,MACnB,mBAAmB;AAAA,MACnB,mBAAmB;AAAA,IACrB;AACA,WAAO,aAAa,KAAK,KAAK;AAAA,EAChC;AAAA,EAEA,MAAc,oBAAoB,UAAmC;AACnE,UAAM,YAAY,MAAM,SAAS,KAAK;AACtC,QAAI;AAEJ,QAAI;AACF,kBAAY,KAAK,MAAM,SAAS;AAAA,IAClC,QAAQ;AACN,kBAAY,EAAE,SAAS,UAAU;AAAA,IACnC;AAEA,UAAM,UAAU,UAAU,WAAW;AAErC,YAAQ,SAAS,QAAQ;AAAA,MACvB,KAAK;AACH,cAAM,IAAI,iCAAoB,SAAS,UAAU,SAAS;AAAA,MAC5D,KAAK;AACH,cAAM,IAAI,4BAAe,SAAS,UAAU,QAAW,SAAS;AAAA,MAClE;AACE,cAAM,IAAI;AAAA,UACR;AAAA,UACA,UAAU,SAAS,MAAM;AAAA,UACzB;AAAA,UACA,SAAS;AAAA,UACT,SAAS,UAAU;AAAA,UACnB;AAAA,QACF;AAAA,IACJ;AAAA,EACF;AACF;",
  "names": []
}
