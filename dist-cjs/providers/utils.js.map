{
  "version": 3,
  "sources": ["../../src/providers/utils.ts"],
  "sourcesContent": ["/**\n * Utility functions for multi-LLM provider system\n */\n\nimport { ILogger } from '../core/logger.js';\nimport { ConfigManager } from '../config/config-manager.js';\nimport { ProviderManager, ProviderManagerConfig } from './provider-manager.js';\nimport { LLMProvider, LLMProviderConfig, FallbackStrategy } from './types.js';\n\n/**\n * Create a provider manager with default configuration\n */\nexport function createProviderManager(\n  logger: ILogger,\n  configManager: ConfigManager,\n  customConfig?: Partial<ProviderManagerConfig>\n): ProviderManager {\n  const defaultConfig = getDefaultProviderConfig();\n  const config = { ...defaultConfig, ...customConfig };\n  \n  // Load provider configs from environment\n  config.providers = loadProviderConfigs(config.providers);\n  \n  return new ProviderManager(logger, configManager, config);\n}\n\n/**\n * Get default provider configuration\n */\nexport function getDefaultProviderConfig(): ProviderManagerConfig {\n  const defaultProvider = (process.env.DEFAULT_LLM_PROVIDER as LLMProvider) || 'anthropic';\n  \n  return {\n    defaultProvider,\n    providers: {\n      anthropic: {\n        provider: 'anthropic',\n        apiKey: process.env.ANTHROPIC_API_KEY,\n        model: 'claude-3-sonnet-20240229',\n        temperature: 0.7,\n        maxTokens: 4096,\n        enableStreaming: true,\n        enableCaching: true,\n        timeout: 60000,\n        retryAttempts: 3,\n      },\n      openai: {\n        provider: 'openai',\n        apiKey: process.env.OPENAI_API_KEY,\n        model: 'gpt-4-turbo-preview',\n        temperature: 0.7,\n        maxTokens: 4096,\n        enableStreaming: true,\n        enableCaching: true,\n        timeout: 60000,\n        retryAttempts: 3,\n      },\n      google: {\n        provider: 'google',\n        apiKey: process.env.GOOGLE_AI_API_KEY,\n        model: 'gemini-pro',\n        temperature: 0.7,\n        maxTokens: 2048,\n        enableStreaming: true,\n        enableCaching: true,\n        timeout: 60000,\n        retryAttempts: 3,\n      },\n      cohere: {\n        provider: 'cohere',\n        apiKey: process.env.COHERE_API_KEY,\n        model: 'command',\n        temperature: 0.7,\n        maxTokens: 4096,\n        enableStreaming: true,\n        enableCaching: true,\n        timeout: 60000,\n        retryAttempts: 3,\n      },\n      ollama: {\n        provider: 'ollama',\n        apiUrl: process.env.OLLAMA_API_URL || 'http://localhost:11434',\n        model: 'llama-2-7b',\n        temperature: 0.7,\n        maxTokens: 2048,\n        enableStreaming: true,\n        enableCaching: false,\n        timeout: 120000, // Longer timeout for local models\n        retryAttempts: 2,\n      },\n    },\n    fallbackStrategy: getDefaultFallbackStrategy(),\n    loadBalancing: {\n      enabled: false,\n      strategy: 'round-robin',\n    },\n    costOptimization: {\n      enabled: true,\n      maxCostPerRequest: 1.0, // $1 max per request\n      preferredProviders: ['anthropic', 'openai'],\n    },\n    caching: {\n      enabled: true,\n      ttl: 3600, // 1 hour\n      maxSize: 100, // 100MB\n      strategy: 'lru',\n    },\n    monitoring: {\n      enabled: true,\n      metricsInterval: 60000, // 1 minute\n    },\n  };\n}\n\n/**\n * Get default fallback strategy\n */\nfunction getDefaultFallbackStrategy(): FallbackStrategy {\n  return {\n    name: 'default',\n    enabled: true,\n    maxAttempts: 3,\n    rules: [\n      {\n        condition: 'rate_limit',\n        fallbackProviders: ['openai', 'google', 'cohere', 'ollama'],\n        retryOriginal: true,\n        retryDelay: 60000, // 1 minute\n      },\n      {\n        condition: 'unavailable',\n        fallbackProviders: ['openai', 'google', 'anthropic', 'cohere'],\n        retryOriginal: true,\n        retryDelay: 30000, // 30 seconds\n      },\n      {\n        condition: 'timeout',\n        fallbackProviders: ['anthropic', 'openai', 'cohere'],\n        retryOriginal: false,\n      },\n      {\n        condition: 'cost',\n        fallbackProviders: ['ollama', 'cohere', 'google'],\n        retryOriginal: false,\n      },\n      {\n        condition: 'error',\n        errorCodes: ['AUTHENTICATION', 'MODEL_NOT_FOUND'],\n        fallbackProviders: [],\n        retryOriginal: false, // Don't retry auth errors\n      },\n    ],\n  };\n}\n\n/**\n * Load provider configurations from environment variables\n */\nfunction loadProviderConfigs(\n  configs: Record<LLMProvider, LLMProviderConfig>\n): Record<LLMProvider, LLMProviderConfig> {\n  const loaded = { ...configs };\n  \n  // Override with environment variables if present\n  for (const [provider, config] of Object.entries(loaded)) {\n    const envPrefix = `${provider.toUpperCase()}_`;\n    \n    // Check for provider-specific overrides\n    if (process.env[`${envPrefix}MODEL`]) {\n      config.model = process.env[`${envPrefix}MODEL`] as any;\n    }\n    if (process.env[`${envPrefix}TEMPERATURE`]) {\n      config.temperature = parseFloat(process.env[`${envPrefix}TEMPERATURE`]);\n    }\n    if (process.env[`${envPrefix}MAX_TOKENS`]) {\n      config.maxTokens = parseInt(process.env[`${envPrefix}MAX_TOKENS`], 10);\n    }\n    if (process.env[`${envPrefix}API_URL`]) {\n      config.apiUrl = process.env[`${envPrefix}API_URL`];\n    }\n  }\n  \n  return loaded;\n}\n\n/**\n * Validate provider configuration\n */\nexport function validateProviderConfig(config: LLMProviderConfig): string[] {\n  const errors: string[] = [];\n  \n  if (!config.provider) {\n    errors.push('Provider name is required');\n  }\n  \n  if (!config.model) {\n    errors.push('Model is required');\n  }\n  \n  if (config.temperature !== undefined) {\n    if (config.temperature < 0 || config.temperature > 2) {\n      errors.push('Temperature must be between 0 and 2');\n    }\n  }\n  \n  if (config.maxTokens !== undefined) {\n    if (config.maxTokens < 1 || config.maxTokens > 100000) {\n      errors.push('Max tokens must be between 1 and 100000');\n    }\n  }\n  \n  if (config.topP !== undefined) {\n    if (config.topP < 0 || config.topP > 1) {\n      errors.push('Top-p must be between 0 and 1');\n    }\n  }\n  \n  if (config.timeout !== undefined) {\n    if (config.timeout < 1000 || config.timeout > 600000) {\n      errors.push('Timeout must be between 1000ms and 600000ms');\n    }\n  }\n  \n  return errors;\n}\n\n/**\n * Get model recommendations based on use case\n */\nexport function getModelRecommendations(useCase: string): {\n  provider: LLMProvider;\n  model: string;\n  reasoning: string;\n}[] {\n  const recommendations: Record<string, any[]> = {\n    'code-generation': [\n      {\n        provider: 'anthropic',\n        model: 'claude-3-opus-20240229',\n        reasoning: 'Best for complex code generation with high accuracy',\n      },\n      {\n        provider: 'openai',\n        model: 'gpt-4-turbo-preview',\n        reasoning: 'Excellent code generation with function calling support',\n      },\n    ],\n    'chat': [\n      {\n        provider: 'anthropic',\n        model: 'claude-3-sonnet-20240229',\n        reasoning: 'Balanced performance for conversational AI',\n      },\n      {\n        provider: 'openai',\n        model: 'gpt-3.5-turbo',\n        reasoning: 'Fast and cost-effective for chat applications',\n      },\n    ],\n    'analysis': [\n      {\n        provider: 'anthropic',\n        model: 'claude-3-opus-20240229',\n        reasoning: 'Excellent for deep analysis and reasoning',\n      },\n      {\n        provider: 'google',\n        model: 'gemini-pro',\n        reasoning: 'Good for data analysis with multimodal support',\n      },\n    ],\n    'local': [\n      {\n        provider: 'ollama',\n        model: 'llama-2-13b',\n        reasoning: 'Good balance of performance and resource usage for local deployment',\n      },\n      {\n        provider: 'ollama',\n        model: 'mistral-7b',\n        reasoning: 'Fast local model with good performance',\n      },\n    ],\n    'budget': [\n      {\n        provider: 'ollama',\n        model: 'llama-2-7b',\n        reasoning: 'Free local model with no API costs',\n      },\n      {\n        provider: 'google',\n        model: 'gemini-pro',\n        reasoning: 'Very cost-effective cloud model',\n      },\n    ],\n  };\n  \n  return recommendations[useCase] || recommendations['chat'];\n}\n\n/**\n * Calculate estimated monthly cost based on usage\n */\nexport function estimateMonthlyCost(\n  provider: LLMProvider,\n  model: string,\n  estimatedRequests: number,\n  avgTokensPerRequest: number\n): {\n  promptCost: number;\n  completionCost: number;\n  totalCost: number;\n  currency: string;\n} {\n  // Get pricing from provider capabilities\n  // This is a simplified calculation\n  const pricing = getPricing(provider, model);\n  \n  if (!pricing) {\n    return {\n      promptCost: 0,\n      completionCost: 0,\n      totalCost: 0,\n      currency: 'USD',\n    };\n  }\n  \n  const promptTokens = avgTokensPerRequest * 0.7; // Assume 70% prompt\n  const completionTokens = avgTokensPerRequest * 0.3; // Assume 30% completion\n  \n  const promptCost = (promptTokens * estimatedRequests / 1000) * pricing.promptCostPer1k;\n  const completionCost = (completionTokens * estimatedRequests / 1000) * pricing.completionCostPer1k;\n  \n  return {\n    promptCost,\n    completionCost,\n    totalCost: promptCost + completionCost,\n    currency: pricing.currency,\n  };\n}\n\n/**\n * Get pricing for a specific provider and model\n */\nfunction getPricing(provider: LLMProvider, model: string): {\n  promptCostPer1k: number;\n  completionCostPer1k: number;\n  currency: string;\n} | null {\n  // This would typically come from provider capabilities\n  // Simplified for example\n  const pricingData: Record<string, any> = {\n    'anthropic:claude-3-opus-20240229': {\n      promptCostPer1k: 0.015,\n      completionCostPer1k: 0.075,\n      currency: 'USD',\n    },\n    'openai:gpt-4-turbo-preview': {\n      promptCostPer1k: 0.01,\n      completionCostPer1k: 0.03,\n      currency: 'USD',\n    },\n    'google:gemini-pro': {\n      promptCostPer1k: 0.00025,\n      completionCostPer1k: 0.0005,\n      currency: 'USD',\n    },\n    'ollama:llama-2-7b': {\n      promptCostPer1k: 0,\n      completionCostPer1k: 0,\n      currency: 'USD',\n    },\n  };\n  \n  return pricingData[`${provider}:${model}`] || null;\n}"],
  "mappings": ";;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAMA,8BAAuD;AAMhD,SAAS,sBACd,QACA,eACA,cACiB;AACjB,QAAM,gBAAgB,yBAAyB;AAC/C,QAAM,SAAS,EAAE,GAAG,eAAe,GAAG,aAAa;AAGnD,SAAO,YAAY,oBAAoB,OAAO,SAAS;AAEvD,SAAO,IAAI,wCAAgB,QAAQ,eAAe,MAAM;AAC1D;AAZgB;AAiBT,SAAS,2BAAkD;AAChE,QAAM,kBAAmB,QAAQ,IAAI,wBAAwC;AAE7E,SAAO;AAAA,IACL;AAAA,IACA,WAAW;AAAA,MACT,WAAW;AAAA,QACT,UAAU;AAAA,QACV,QAAQ,QAAQ,IAAI;AAAA,QACpB,OAAO;AAAA,QACP,aAAa;AAAA,QACb,WAAW;AAAA,QACX,iBAAiB;AAAA,QACjB,eAAe;AAAA,QACf,SAAS;AAAA,QACT,eAAe;AAAA,MACjB;AAAA,MACA,QAAQ;AAAA,QACN,UAAU;AAAA,QACV,QAAQ,QAAQ,IAAI;AAAA,QACpB,OAAO;AAAA,QACP,aAAa;AAAA,QACb,WAAW;AAAA,QACX,iBAAiB;AAAA,QACjB,eAAe;AAAA,QACf,SAAS;AAAA,QACT,eAAe;AAAA,MACjB;AAAA,MACA,QAAQ;AAAA,QACN,UAAU;AAAA,QACV,QAAQ,QAAQ,IAAI;AAAA,QACpB,OAAO;AAAA,QACP,aAAa;AAAA,QACb,WAAW;AAAA,QACX,iBAAiB;AAAA,QACjB,eAAe;AAAA,QACf,SAAS;AAAA,QACT,eAAe;AAAA,MACjB;AAAA,MACA,QAAQ;AAAA,QACN,UAAU;AAAA,QACV,QAAQ,QAAQ,IAAI;AAAA,QACpB,OAAO;AAAA,QACP,aAAa;AAAA,QACb,WAAW;AAAA,QACX,iBAAiB;AAAA,QACjB,eAAe;AAAA,QACf,SAAS;AAAA,QACT,eAAe;AAAA,MACjB;AAAA,MACA,QAAQ;AAAA,QACN,UAAU;AAAA,QACV,QAAQ,QAAQ,IAAI,kBAAkB;AAAA,QACtC,OAAO;AAAA,QACP,aAAa;AAAA,QACb,WAAW;AAAA,QACX,iBAAiB;AAAA,QACjB,eAAe;AAAA,QACf,SAAS;AAAA;AAAA,QACT,eAAe;AAAA,MACjB;AAAA,IACF;AAAA,IACA,kBAAkB,2BAA2B;AAAA,IAC7C,eAAe;AAAA,MACb,SAAS;AAAA,MACT,UAAU;AAAA,IACZ;AAAA,IACA,kBAAkB;AAAA,MAChB,SAAS;AAAA,MACT,mBAAmB;AAAA;AAAA,MACnB,oBAAoB,CAAC,aAAa,QAAQ;AAAA,IAC5C;AAAA,IACA,SAAS;AAAA,MACP,SAAS;AAAA,MACT,KAAK;AAAA;AAAA,MACL,SAAS;AAAA;AAAA,MACT,UAAU;AAAA,IACZ;AAAA,IACA,YAAY;AAAA,MACV,SAAS;AAAA,MACT,iBAAiB;AAAA;AAAA,IACnB;AAAA,EACF;AACF;AAnFgB;AAwFhB,SAAS,6BAA+C;AACtD,SAAO;AAAA,IACL,MAAM;AAAA,IACN,SAAS;AAAA,IACT,aAAa;AAAA,IACb,OAAO;AAAA,MACL;AAAA,QACE,WAAW;AAAA,QACX,mBAAmB,CAAC,UAAU,UAAU,UAAU,QAAQ;AAAA,QAC1D,eAAe;AAAA,QACf,YAAY;AAAA;AAAA,MACd;AAAA,MACA;AAAA,QACE,WAAW;AAAA,QACX,mBAAmB,CAAC,UAAU,UAAU,aAAa,QAAQ;AAAA,QAC7D,eAAe;AAAA,QACf,YAAY;AAAA;AAAA,MACd;AAAA,MACA;AAAA,QACE,WAAW;AAAA,QACX,mBAAmB,CAAC,aAAa,UAAU,QAAQ;AAAA,QACnD,eAAe;AAAA,MACjB;AAAA,MACA;AAAA,QACE,WAAW;AAAA,QACX,mBAAmB,CAAC,UAAU,UAAU,QAAQ;AAAA,QAChD,eAAe;AAAA,MACjB;AAAA,MACA;AAAA,QACE,WAAW;AAAA,QACX,YAAY,CAAC,kBAAkB,iBAAiB;AAAA,QAChD,mBAAmB,CAAC;AAAA,QACpB,eAAe;AAAA;AAAA,MACjB;AAAA,IACF;AAAA,EACF;AACF;AApCS;AAyCT,SAAS,oBACP,SACwC;AACxC,QAAM,SAAS,EAAE,GAAG,QAAQ;AAG5B,aAAW,CAAC,UAAU,MAAM,KAAK,OAAO,QAAQ,MAAM,GAAG;AACvD,UAAM,YAAY,GAAG,SAAS,YAAY,CAAC;AAG3C,QAAI,QAAQ,IAAI,GAAG,SAAS,OAAO,GAAG;AACpC,aAAO,QAAQ,QAAQ,IAAI,GAAG,SAAS,OAAO;AAAA,IAChD;AACA,QAAI,QAAQ,IAAI,GAAG,SAAS,aAAa,GAAG;AAC1C,aAAO,cAAc,WAAW,QAAQ,IAAI,GAAG,SAAS,aAAa,CAAC;AAAA,IACxE;AACA,QAAI,QAAQ,IAAI,GAAG,SAAS,YAAY,GAAG;AACzC,aAAO,YAAY,SAAS,QAAQ,IAAI,GAAG,SAAS,YAAY,GAAG,EAAE;AAAA,IACvE;AACA,QAAI,QAAQ,IAAI,GAAG,SAAS,SAAS,GAAG;AACtC,aAAO,SAAS,QAAQ,IAAI,GAAG,SAAS,SAAS;AAAA,IACnD;AAAA,EACF;AAEA,SAAO;AACT;AAzBS;AA8BF,SAAS,uBAAuB,QAAqC;AAC1E,QAAM,SAAmB,CAAC;AAE1B,MAAI,CAAC,OAAO,UAAU;AACpB,WAAO,KAAK,2BAA2B;AAAA,EACzC;AAEA,MAAI,CAAC,OAAO,OAAO;AACjB,WAAO,KAAK,mBAAmB;AAAA,EACjC;AAEA,MAAI,OAAO,gBAAgB,QAAW;AACpC,QAAI,OAAO,cAAc,KAAK,OAAO,cAAc,GAAG;AACpD,aAAO,KAAK,qCAAqC;AAAA,IACnD;AAAA,EACF;AAEA,MAAI,OAAO,cAAc,QAAW;AAClC,QAAI,OAAO,YAAY,KAAK,OAAO,YAAY,KAAQ;AACrD,aAAO,KAAK,yCAAyC;AAAA,IACvD;AAAA,EACF;AAEA,MAAI,OAAO,SAAS,QAAW;AAC7B,QAAI,OAAO,OAAO,KAAK,OAAO,OAAO,GAAG;AACtC,aAAO,KAAK,+BAA+B;AAAA,IAC7C;AAAA,EACF;AAEA,MAAI,OAAO,YAAY,QAAW;AAChC,QAAI,OAAO,UAAU,OAAQ,OAAO,UAAU,KAAQ;AACpD,aAAO,KAAK,6CAA6C;AAAA,IAC3D;AAAA,EACF;AAEA,SAAO;AACT;AApCgB;AAyCT,SAAS,wBAAwB,SAIpC;AACF,QAAM,kBAAyC;AAAA,IAC7C,mBAAmB;AAAA,MACjB;AAAA,QACE,UAAU;AAAA,QACV,OAAO;AAAA,QACP,WAAW;AAAA,MACb;AAAA,MACA;AAAA,QACE,UAAU;AAAA,QACV,OAAO;AAAA,QACP,WAAW;AAAA,MACb;AAAA,IACF;AAAA,IACA,QAAQ;AAAA,MACN;AAAA,QACE,UAAU;AAAA,QACV,OAAO;AAAA,QACP,WAAW;AAAA,MACb;AAAA,MACA;AAAA,QACE,UAAU;AAAA,QACV,OAAO;AAAA,QACP,WAAW;AAAA,MACb;AAAA,IACF;AAAA,IACA,YAAY;AAAA,MACV;AAAA,QACE,UAAU;AAAA,QACV,OAAO;AAAA,QACP,WAAW;AAAA,MACb;AAAA,MACA;AAAA,QACE,UAAU;AAAA,QACV,OAAO;AAAA,QACP,WAAW;AAAA,MACb;AAAA,IACF;AAAA,IACA,SAAS;AAAA,MACP;AAAA,QACE,UAAU;AAAA,QACV,OAAO;AAAA,QACP,WAAW;AAAA,MACb;AAAA,MACA;AAAA,QACE,UAAU;AAAA,QACV,OAAO;AAAA,QACP,WAAW;AAAA,MACb;AAAA,IACF;AAAA,IACA,UAAU;AAAA,MACR;AAAA,QACE,UAAU;AAAA,QACV,OAAO;AAAA,QACP,WAAW;AAAA,MACb;AAAA,MACA;AAAA,QACE,UAAU;AAAA,QACV,OAAO;AAAA,QACP,WAAW;AAAA,MACb;AAAA,IACF;AAAA,EACF;AAEA,SAAO,gBAAgB,OAAO,KAAK,gBAAgB,MAAM;AAC3D;AArEgB;AA0ET,SAAS,oBACd,UACA,OACA,mBACA,qBAMA;AAGA,QAAM,UAAU,WAAW,UAAU,KAAK;AAE1C,MAAI,CAAC,SAAS;AACZ,WAAO;AAAA,MACL,YAAY;AAAA,MACZ,gBAAgB;AAAA,MAChB,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAEA,QAAM,eAAe,sBAAsB;AAC3C,QAAM,mBAAmB,sBAAsB;AAE/C,QAAM,aAAc,eAAe,oBAAoB,MAAQ,QAAQ;AACvE,QAAM,iBAAkB,mBAAmB,oBAAoB,MAAQ,QAAQ;AAE/E,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA,WAAW,aAAa;AAAA,IACxB,UAAU,QAAQ;AAAA,EACpB;AACF;AApCgB;AAyChB,SAAS,WAAW,UAAuB,OAIlC;AAGP,QAAM,cAAmC;AAAA,IACvC,oCAAoC;AAAA,MAClC,iBAAiB;AAAA,MACjB,qBAAqB;AAAA,MACrB,UAAU;AAAA,IACZ;AAAA,IACA,8BAA8B;AAAA,MAC5B,iBAAiB;AAAA,MACjB,qBAAqB;AAAA,MACrB,UAAU;AAAA,IACZ;AAAA,IACA,qBAAqB;AAAA,MACnB,iBAAiB;AAAA,MACjB,qBAAqB;AAAA,MACrB,UAAU;AAAA,IACZ;AAAA,IACA,qBAAqB;AAAA,MACnB,iBAAiB;AAAA,MACjB,qBAAqB;AAAA,MACrB,UAAU;AAAA,IACZ;AAAA,EACF;AAEA,SAAO,YAAY,GAAG,QAAQ,IAAI,KAAK,EAAE,KAAK;AAChD;AA/BS;",
  "names": []
}
