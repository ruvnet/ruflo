{"version":3,"sources":["../../../src/providers/anthropic-provider.ts"],"sourcesContent":["/**\r\n * Anthropic (Claude) Provider Implementation\r\n * Extends the existing Claude client with unified provider interface\r\n */\r\n\r\nimport { BaseProvider } from './base-provider.js';\r\nimport { ClaudeAPIClient, ClaudeModel as AnthropicModel } from '../api/claude-client.js';\r\nimport {\r\n  LLMProvider,\r\n  LLMModel,\r\n  LLMRequest,\r\n  LLMResponse,\r\n  LLMStreamEvent,\r\n  ModelInfo,\r\n  ProviderCapabilities,\r\n  HealthCheckResult,\r\n  LLMProviderError,\r\n} from './types.js';\r\n\r\nexport class AnthropicProvider extends BaseProvider {\r\n  readonly name: LLMProvider = 'anthropic';\r\n  readonly capabilities: ProviderCapabilities = {\r\n    supportedModels: [\r\n      'claude-3-opus-20240229',\r\n      'claude-3-sonnet-20240229',\r\n      'claude-3-haiku-20240307',\r\n      'claude-2.1',\r\n      'claude-2.0',\r\n      'claude-instant-1.2',\r\n    ],\r\n    maxContextLength: {\r\n      'claude-3-opus-20240229': 200000,\r\n      'claude-3-sonnet-20240229': 200000,\r\n      'claude-3-haiku-20240307': 200000,\r\n      'claude-2.1': 200000,\r\n      'claude-2.0': 100000,\r\n      'claude-instant-1.2': 100000,\r\n    } as Record<LLMModel, number>,\r\n    maxOutputTokens: {\r\n      'claude-3-opus-20240229': 4096,\r\n      'claude-3-sonnet-20240229': 4096,\r\n      'claude-3-haiku-20240307': 4096,\r\n      'claude-2.1': 4096,\r\n      'claude-2.0': 4096,\r\n      'claude-instant-1.2': 4096,\r\n    } as Record<LLMModel, number>,\r\n    supportsStreaming: true,\r\n    supportsFunctionCalling: false, // Claude doesn't have native function calling yet\r\n    supportsSystemMessages: true,\r\n    supportsVision: true, // Claude 3 models support vision\r\n    supportsAudio: false,\r\n    supportsTools: false,\r\n    supportsFineTuning: false,\r\n    supportsEmbeddings: false,\r\n    supportsLogprobs: false,\r\n    supportsBatching: false,\r\n    pricing: {\r\n      'claude-3-opus-20240229': {\r\n        promptCostPer1k: 0.015,\r\n        completionCostPer1k: 0.075,\r\n        currency: 'USD',\r\n      },\r\n      'claude-3-sonnet-20240229': {\r\n        promptCostPer1k: 0.003,\r\n        completionCostPer1k: 0.015,\r\n        currency: 'USD',\r\n      },\r\n      'claude-3-haiku-20240307': {\r\n        promptCostPer1k: 0.00025,\r\n        completionCostPer1k: 0.00125,\r\n        currency: 'USD',\r\n      },\r\n      'claude-2.1': {\r\n        promptCostPer1k: 0.008,\r\n        completionCostPer1k: 0.024,\r\n        currency: 'USD',\r\n      },\r\n      'claude-2.0': {\r\n        promptCostPer1k: 0.008,\r\n        completionCostPer1k: 0.024,\r\n        currency: 'USD',\r\n      },\r\n      'claude-instant-1.2': {\r\n        promptCostPer1k: 0.0008,\r\n        completionCostPer1k: 0.0024,\r\n        currency: 'USD',\r\n      },\r\n    },\r\n  };\r\n\r\n  private claudeClient!: ClaudeAPIClient;\r\n\r\n  protected async doInitialize(): Promise<void> {\r\n    // Create Claude client with our config\r\n    this.claudeClient = new ClaudeAPIClient(\r\n      this.logger,\r\n      { get: () => this.config } as any, // Mock config manager\r\n      {\r\n        apiKey: this.config.apiKey!,\r\n        model: this.mapToAnthropicModel(this.config.model),\r\n        temperature: this.config.temperature,\r\n        maxTokens: this.config.maxTokens,\r\n        topP: this.config.topP,\r\n        topK: this.config.topK,\r\n        timeout: this.config.timeout,\r\n        retryAttempts: this.config.retryAttempts,\r\n        retryDelay: this.config.retryDelay,\r\n      }\r\n    );\r\n  }\r\n\r\n  protected async doComplete(request: LLMRequest): Promise<LLMResponse> {\r\n    // Convert request to Claude format\r\n    const claudeMessages = request.messages.map((msg) => ({\r\n      role: msg.role === 'system' ? 'user' : msg.role as 'user' | 'assistant',\r\n      content: msg.role === 'system' ? `System: ${msg.content}` : msg.content,\r\n    }));\r\n\r\n    // Extract system message if present\r\n    const systemMessage = request.messages.find((m) => m.role === 'system');\r\n    \r\n    // Call Claude API\r\n    const response = await this.claudeClient.sendMessage(claudeMessages, {\r\n      model: request.model ? this.mapToAnthropicModel(request.model) : undefined,\r\n      temperature: request.temperature,\r\n      maxTokens: request.maxTokens,\r\n      systemPrompt: systemMessage?.content,\r\n      stream: false,\r\n    }) as any; // ClaudeResponse type\r\n\r\n    // Calculate cost\r\n    const pricing = this.capabilities.pricing![response.model];\r\n    const promptCost = (response.usage.input_tokens / 1000) * pricing.promptCostPer1k;\r\n    const completionCost = (response.usage.output_tokens / 1000) * pricing.completionCostPer1k;\r\n\r\n    // Convert to unified response format\r\n    return {\r\n      id: response.id,\r\n      model: this.mapFromAnthropicModel(response.model),\r\n      provider: 'anthropic',\r\n      content: response.content[0].text,\r\n      usage: {\r\n        promptTokens: response.usage.input_tokens,\r\n        completionTokens: response.usage.output_tokens,\r\n        totalTokens: response.usage.input_tokens + response.usage.output_tokens,\r\n      },\r\n      cost: {\r\n        promptCost,\r\n        completionCost,\r\n        totalCost: promptCost + completionCost,\r\n        currency: 'USD',\r\n      },\r\n      finishReason: response.stop_reason === 'end_turn' ? 'stop' : 'length',\r\n    };\r\n  }\r\n\r\n  protected async *doStreamComplete(request: LLMRequest): AsyncIterable<LLMStreamEvent> {\r\n    // Convert request to Claude format\r\n    const claudeMessages = request.messages.map((msg) => ({\r\n      role: msg.role === 'system' ? 'user' : msg.role as 'user' | 'assistant',\r\n      content: msg.role === 'system' ? `System: ${msg.content}` : msg.content,\r\n    }));\r\n\r\n    const systemMessage = request.messages.find((m) => m.role === 'system');\r\n    \r\n    // Get stream from Claude API\r\n    const stream = await this.claudeClient.sendMessage(claudeMessages, {\r\n      model: request.model ? this.mapToAnthropicModel(request.model) : undefined,\r\n      temperature: request.temperature,\r\n      maxTokens: request.maxTokens,\r\n      systemPrompt: systemMessage?.content,\r\n      stream: true,\r\n    }) as AsyncIterable<any>; // ClaudeStreamEvent type\r\n\r\n    let accumulatedContent = '';\r\n    let totalTokens = 0;\r\n\r\n    // Process stream events\r\n    for await (const event of stream) {\r\n      if (event.type === 'content_block_delta' && event.delta?.text) {\r\n        accumulatedContent += event.delta.text;\r\n        yield {\r\n          type: 'content',\r\n          delta: {\r\n            content: event.delta.text,\r\n          },\r\n        };\r\n      } else if (event.type === 'message_delta' && event.usage) {\r\n        totalTokens = event.usage.output_tokens;\r\n      } else if (event.type === 'message_stop') {\r\n        // Calculate final cost\r\n        const model = request.model || this.config.model;\r\n        const pricing = this.capabilities.pricing![model];\r\n        \r\n        // Estimate prompt tokens (rough approximation)\r\n        const promptTokens = this.estimateTokens(JSON.stringify(request.messages));\r\n        const completionTokens = totalTokens;\r\n        \r\n        const promptCost = (promptTokens / 1000) * pricing.promptCostPer1k;\r\n        const completionCost = (completionTokens / 1000) * pricing.completionCostPer1k;\r\n\r\n        yield {\r\n          type: 'done',\r\n          usage: {\r\n            promptTokens,\r\n            completionTokens,\r\n            totalTokens: promptTokens + completionTokens,\r\n          },\r\n          cost: {\r\n            promptCost,\r\n            completionCost,\r\n            totalCost: promptCost + completionCost,\r\n            currency: 'USD',\r\n          },\r\n        };\r\n      }\r\n    }\r\n  }\r\n\r\n  async listModels(): Promise<LLMModel[]> {\r\n    return this.capabilities.supportedModels;\r\n  }\r\n\r\n  async getModelInfo(model: LLMModel): Promise<ModelInfo> {\r\n    const anthropicModel = this.mapToAnthropicModel(model);\r\n    const info = this.claudeClient.getModelInfo(anthropicModel);\r\n    \r\n    return {\r\n      model,\r\n      name: info.name,\r\n      description: info.description,\r\n      contextLength: info.contextWindow,\r\n      maxOutputTokens: this.capabilities.maxOutputTokens[model] || 4096,\r\n      supportedFeatures: [\r\n        'chat',\r\n        'completion',\r\n        ...(model.startsWith('claude-3') ? ['vision'] : []),\r\n      ],\r\n      pricing: this.capabilities.pricing![model],\r\n    };\r\n  }\r\n\r\n  protected async doHealthCheck(): Promise<HealthCheckResult> {\r\n    try {\r\n      // Use a minimal request to check API availability\r\n      await this.claudeClient.complete('Hi', {\r\n        maxTokens: 1,\r\n      });\r\n      \r\n      return {\r\n        healthy: true,\r\n        timestamp: new Date(),\r\n      };\r\n    } catch (error) {\r\n      return {\r\n        healthy: false,\r\n        error: error instanceof Error ? error.message : 'Unknown error',\r\n        timestamp: new Date(),\r\n      };\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Map unified model to Anthropic model\r\n   */\r\n  private mapToAnthropicModel(model: LLMModel): AnthropicModel {\r\n    // Direct mapping since we use the same model names\r\n    return model as AnthropicModel;\r\n  }\r\n\r\n  /**\r\n   * Map Anthropic model to unified model\r\n   */\r\n  private mapFromAnthropicModel(model: AnthropicModel): LLMModel {\r\n    return model as LLMModel;\r\n  }\r\n\r\n  destroy(): void {\r\n    super.destroy();\r\n    this.claudeClient?.destroy();\r\n  }\r\n}"],"names":["BaseProvider","ClaudeAPIClient","AnthropicProvider","name","capabilities","supportedModels","maxContextLength","maxOutputTokens","supportsStreaming","supportsFunctionCalling","supportsSystemMessages","supportsVision","supportsAudio","supportsTools","supportsFineTuning","supportsEmbeddings","supportsLogprobs","supportsBatching","pricing","promptCostPer1k","completionCostPer1k","currency","claudeClient","doInitialize","logger","get","config","apiKey","model","mapToAnthropicModel","temperature","maxTokens","topP","topK","timeout","retryAttempts","retryDelay","doComplete","request","claudeMessages","messages","map","msg","role","content","systemMessage","find","m","response","sendMessage","undefined","systemPrompt","stream","promptCost","usage","input_tokens","completionCost","output_tokens","id","mapFromAnthropicModel","provider","text","promptTokens","completionTokens","totalTokens","cost","totalCost","finishReason","stop_reason","doStreamComplete","accumulatedContent","event","type","delta","estimateTokens","JSON","stringify","listModels","getModelInfo","anthropicModel","info","description","contextLength","contextWindow","supportedFeatures","startsWith","doHealthCheck","complete","healthy","timestamp","Date","error","Error","message","destroy"],"mappings":"AAKA,SAASA,YAAY,QAAQ,qBAAqB;AAClD,SAASC,eAAe,QAAuC,0BAA0B;AAazF,OAAO,MAAMC,0BAA0BF;IAC5BG,OAAoB,YAAY;IAChCC,eAAqC;QAC5CC,iBAAiB;YACf;YACA;YACA;YACA;YACA;YACA;SACD;QACDC,kBAAkB;YAChB,0BAA0B;YAC1B,4BAA4B;YAC5B,2BAA2B;YAC3B,cAAc;YACd,cAAc;YACd,sBAAsB;QACxB;QACAC,iBAAiB;YACf,0BAA0B;YAC1B,4BAA4B;YAC5B,2BAA2B;YAC3B,cAAc;YACd,cAAc;YACd,sBAAsB;QACxB;QACAC,mBAAmB;QACnBC,yBAAyB;QACzBC,wBAAwB;QACxBC,gBAAgB;QAChBC,eAAe;QACfC,eAAe;QACfC,oBAAoB;QACpBC,oBAAoB;QACpBC,kBAAkB;QAClBC,kBAAkB;QAClBC,SAAS;YACP,0BAA0B;gBACxBC,iBAAiB;gBACjBC,qBAAqB;gBACrBC,UAAU;YACZ;YACA,4BAA4B;gBAC1BF,iBAAiB;gBACjBC,qBAAqB;gBACrBC,UAAU;YACZ;YACA,2BAA2B;gBACzBF,iBAAiB;gBACjBC,qBAAqB;gBACrBC,UAAU;YACZ;YACA,cAAc;gBACZF,iBAAiB;gBACjBC,qBAAqB;gBACrBC,UAAU;YACZ;YACA,cAAc;gBACZF,iBAAiB;gBACjBC,qBAAqB;gBACrBC,UAAU;YACZ;YACA,sBAAsB;gBACpBF,iBAAiB;gBACjBC,qBAAqB;gBACrBC,UAAU;YACZ;QACF;IACF,EAAE;IAEMC,aAA+B;IAEvC,MAAgBC,eAA8B;QAE5C,IAAI,CAACD,YAAY,GAAG,IAAIrB,gBACtB,IAAI,CAACuB,MAAM,EACX;YAAEC,KAAK,IAAM,IAAI,CAACC,MAAM;QAAC,GACzB;YACEC,QAAQ,IAAI,CAACD,MAAM,CAACC,MAAM;YAC1BC,OAAO,IAAI,CAACC,mBAAmB,CAAC,IAAI,CAACH,MAAM,CAACE,KAAK;YACjDE,aAAa,IAAI,CAACJ,MAAM,CAACI,WAAW;YACpCC,WAAW,IAAI,CAACL,MAAM,CAACK,SAAS;YAChCC,MAAM,IAAI,CAACN,MAAM,CAACM,IAAI;YACtBC,MAAM,IAAI,CAACP,MAAM,CAACO,IAAI;YACtBC,SAAS,IAAI,CAACR,MAAM,CAACQ,OAAO;YAC5BC,eAAe,IAAI,CAACT,MAAM,CAACS,aAAa;YACxCC,YAAY,IAAI,CAACV,MAAM,CAACU,UAAU;QACpC;IAEJ;IAEA,MAAgBC,WAAWC,OAAmB,EAAwB;QAEpE,MAAMC,iBAAiBD,QAAQE,QAAQ,CAACC,GAAG,CAAC,CAACC,MAAS,CAAA;gBACpDC,MAAMD,IAAIC,IAAI,KAAK,WAAW,SAASD,IAAIC,IAAI;gBAC/CC,SAASF,IAAIC,IAAI,KAAK,WAAW,CAAC,QAAQ,EAAED,IAAIE,OAAO,EAAE,GAAGF,IAAIE,OAAO;YACzE,CAAA;QAGA,MAAMC,gBAAgBP,QAAQE,QAAQ,CAACM,IAAI,CAAC,CAACC,IAAMA,EAAEJ,IAAI,KAAK;QAG9D,MAAMK,WAAW,MAAM,IAAI,CAAC1B,YAAY,CAAC2B,WAAW,CAACV,gBAAgB;YACnEX,OAAOU,QAAQV,KAAK,GAAG,IAAI,CAACC,mBAAmB,CAACS,QAAQV,KAAK,IAAIsB;YACjEpB,aAAaQ,QAAQR,WAAW;YAChCC,WAAWO,QAAQP,SAAS;YAC5BoB,cAAcN,eAAeD;YAC7BQ,QAAQ;QACV;QAGA,MAAMlC,UAAU,IAAI,CAACd,YAAY,CAACc,OAAO,AAAC,CAAC8B,SAASpB,KAAK,CAAC;QAC1D,MAAMyB,aAAa,AAACL,SAASM,KAAK,CAACC,YAAY,GAAG,OAAQrC,QAAQC,eAAe;QACjF,MAAMqC,iBAAiB,AAACR,SAASM,KAAK,CAACG,aAAa,GAAG,OAAQvC,QAAQE,mBAAmB;QAG1F,OAAO;YACLsC,IAAIV,SAASU,EAAE;YACf9B,OAAO,IAAI,CAAC+B,qBAAqB,CAACX,SAASpB,KAAK;YAChDgC,UAAU;YACVhB,SAASI,SAASJ,OAAO,CAAC,EAAE,CAACiB,IAAI;YACjCP,OAAO;gBACLQ,cAAcd,SAASM,KAAK,CAACC,YAAY;gBACzCQ,kBAAkBf,SAASM,KAAK,CAACG,aAAa;gBAC9CO,aAAahB,SAASM,KAAK,CAACC,YAAY,GAAGP,SAASM,KAAK,CAACG,aAAa;YACzE;YACAQ,MAAM;gBACJZ;gBACAG;gBACAU,WAAWb,aAAaG;gBACxBnC,UAAU;YACZ;YACA8C,cAAcnB,SAASoB,WAAW,KAAK,aAAa,SAAS;QAC/D;IACF;IAEA,OAAiBC,iBAAiB/B,OAAmB,EAAiC;QAEpF,MAAMC,iBAAiBD,QAAQE,QAAQ,CAACC,GAAG,CAAC,CAACC,MAAS,CAAA;gBACpDC,MAAMD,IAAIC,IAAI,KAAK,WAAW,SAASD,IAAIC,IAAI;gBAC/CC,SAASF,IAAIC,IAAI,KAAK,WAAW,CAAC,QAAQ,EAAED,IAAIE,OAAO,EAAE,GAAGF,IAAIE,OAAO;YACzE,CAAA;QAEA,MAAMC,gBAAgBP,QAAQE,QAAQ,CAACM,IAAI,CAAC,CAACC,IAAMA,EAAEJ,IAAI,KAAK;QAG9D,MAAMS,SAAS,MAAM,IAAI,CAAC9B,YAAY,CAAC2B,WAAW,CAACV,gBAAgB;YACjEX,OAAOU,QAAQV,KAAK,GAAG,IAAI,CAACC,mBAAmB,CAACS,QAAQV,KAAK,IAAIsB;YACjEpB,aAAaQ,QAAQR,WAAW;YAChCC,WAAWO,QAAQP,SAAS;YAC5BoB,cAAcN,eAAeD;YAC7BQ,QAAQ;QACV;QAEA,IAAIkB,qBAAqB;QACzB,IAAIN,cAAc;QAGlB,WAAW,MAAMO,SAASnB,OAAQ;YAChC,IAAImB,MAAMC,IAAI,KAAK,yBAAyBD,MAAME,KAAK,EAAEZ,MAAM;gBAC7DS,sBAAsBC,MAAME,KAAK,CAACZ,IAAI;gBACtC,MAAM;oBACJW,MAAM;oBACNC,OAAO;wBACL7B,SAAS2B,MAAME,KAAK,CAACZ,IAAI;oBAC3B;gBACF;YACF,OAAO,IAAIU,MAAMC,IAAI,KAAK,mBAAmBD,MAAMjB,KAAK,EAAE;gBACxDU,cAAcO,MAAMjB,KAAK,CAACG,aAAa;YACzC,OAAO,IAAIc,MAAMC,IAAI,KAAK,gBAAgB;gBAExC,MAAM5C,QAAQU,QAAQV,KAAK,IAAI,IAAI,CAACF,MAAM,CAACE,KAAK;gBAChD,MAAMV,UAAU,IAAI,CAACd,YAAY,CAACc,OAAO,AAAC,CAACU,MAAM;gBAGjD,MAAMkC,eAAe,IAAI,CAACY,cAAc,CAACC,KAAKC,SAAS,CAACtC,QAAQE,QAAQ;gBACxE,MAAMuB,mBAAmBC;gBAEzB,MAAMX,aAAa,AAACS,eAAe,OAAQ5C,QAAQC,eAAe;gBAClE,MAAMqC,iBAAiB,AAACO,mBAAmB,OAAQ7C,QAAQE,mBAAmB;gBAE9E,MAAM;oBACJoD,MAAM;oBACNlB,OAAO;wBACLQ;wBACAC;wBACAC,aAAaF,eAAeC;oBAC9B;oBACAE,MAAM;wBACJZ;wBACAG;wBACAU,WAAWb,aAAaG;wBACxBnC,UAAU;oBACZ;gBACF;YACF;QACF;IACF;IAEA,MAAMwD,aAAkC;QACtC,OAAO,IAAI,CAACzE,YAAY,CAACC,eAAe;IAC1C;IAEA,MAAMyE,aAAalD,KAAe,EAAsB;QACtD,MAAMmD,iBAAiB,IAAI,CAAClD,mBAAmB,CAACD;QAChD,MAAMoD,OAAO,IAAI,CAAC1D,YAAY,CAACwD,YAAY,CAACC;QAE5C,OAAO;YACLnD;YACAzB,MAAM6E,KAAK7E,IAAI;YACf8E,aAAaD,KAAKC,WAAW;YAC7BC,eAAeF,KAAKG,aAAa;YACjC5E,iBAAiB,IAAI,CAACH,YAAY,CAACG,eAAe,CAACqB,MAAM,IAAI;YAC7DwD,mBAAmB;gBACjB;gBACA;mBACIxD,MAAMyD,UAAU,CAAC,cAAc;oBAAC;iBAAS,GAAG,EAAE;aACnD;YACDnE,SAAS,IAAI,CAACd,YAAY,CAACc,OAAO,AAAC,CAACU,MAAM;QAC5C;IACF;IAEA,MAAgB0D,gBAA4C;QAC1D,IAAI;YAEF,MAAM,IAAI,CAAChE,YAAY,CAACiE,QAAQ,CAAC,MAAM;gBACrCxD,WAAW;YACb;YAEA,OAAO;gBACLyD,SAAS;gBACTC,WAAW,IAAIC;YACjB;QACF,EAAE,OAAOC,OAAO;YACd,OAAO;gBACLH,SAAS;gBACTG,OAAOA,iBAAiBC,QAAQD,MAAME,OAAO,GAAG;gBAChDJ,WAAW,IAAIC;YACjB;QACF;IACF;IAKQ7D,oBAAoBD,KAAe,EAAkB;QAE3D,OAAOA;IACT;IAKQ+B,sBAAsB/B,KAAqB,EAAY;QAC7D,OAAOA;IACT;IAEAkE,UAAgB;QACd,KAAK,CAACA;QACN,IAAI,CAACxE,YAAY,EAAEwE;IACrB;AACF"}