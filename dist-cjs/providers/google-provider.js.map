{
  "version": 3,
  "sources": ["../../src/providers/google-provider.ts"],
  "sourcesContent": ["/**\n * Google AI Provider Implementation\n * Supports Gemini Pro, PaLM, and other Google models\n */\n\nimport { BaseProvider } from './base-provider.js';\nimport {\n  LLMProvider,\n  LLMModel,\n  LLMRequest,\n  LLMResponse,\n  LLMStreamEvent,\n  ModelInfo,\n  ProviderCapabilities,\n  HealthCheckResult,\n  LLMProviderError,\n  RateLimitError,\n  AuthenticationError,\n} from './types.js';\n\ninterface GoogleAIRequest {\n  contents: Array<{\n    role: 'user' | 'model';\n    parts: Array<{\n      text?: string;\n      inlineData?: {\n        mimeType: string;\n        data: string;\n      };\n    }>;\n  }>;\n  generationConfig?: {\n    temperature?: number;\n    topK?: number;\n    topP?: number;\n    maxOutputTokens?: number;\n    stopSequences?: string[];\n  };\n  safetySettings?: Array<{\n    category: string;\n    threshold: string;\n  }>;\n}\n\ninterface GoogleAIResponse {\n  candidates: Array<{\n    content: {\n      parts: Array<{\n        text: string;\n      }>;\n      role: string;\n    };\n    finishReason: string;\n    index: number;\n    safetyRatings: Array<{\n      category: string;\n      probability: string;\n    }>;\n  }>;\n  promptFeedback?: {\n    safetyRatings: Array<{\n      category: string;\n      probability: string;\n    }>;\n  };\n  usageMetadata?: {\n    promptTokenCount: number;\n    candidatesTokenCount: number;\n    totalTokenCount: number;\n  };\n}\n\nexport class GoogleProvider extends BaseProvider {\n  readonly name: LLMProvider = 'google';\n  readonly capabilities: ProviderCapabilities = {\n    supportedModels: [\n      'gemini-pro',\n      'gemini-pro-vision',\n      'palm-2',\n      'bison',\n    ],\n    maxContextLength: {\n      'gemini-pro': 32768,\n      'gemini-pro-vision': 16384,\n      'palm-2': 8192,\n      'bison': 4096,\n    } as Record<LLMModel, number>,\n    maxOutputTokens: {\n      'gemini-pro': 2048,\n      'gemini-pro-vision': 2048,\n      'palm-2': 1024,\n      'bison': 1024,\n    } as Record<LLMModel, number>,\n    supportsStreaming: true,\n    supportsFunctionCalling: true,\n    supportsSystemMessages: false, // Google AI doesn't have explicit system messages\n    supportsVision: true, // Gemini Pro Vision\n    supportsAudio: false,\n    supportsTools: true,\n    supportsFineTuning: false,\n    supportsEmbeddings: true,\n    supportsLogprobs: false,\n    supportsBatching: true,\n    rateLimit: {\n      requestsPerMinute: 60,\n      tokensPerMinute: 60000,\n      concurrentRequests: 10,\n    },\n    pricing: {\n      'gemini-pro': {\n        promptCostPer1k: 0.00025,\n        completionCostPer1k: 0.0005,\n        currency: 'USD',\n      },\n      'gemini-pro-vision': {\n        promptCostPer1k: 0.00025,\n        completionCostPer1k: 0.0005,\n        currency: 'USD',\n      },\n      'palm-2': {\n        promptCostPer1k: 0.0005,\n        completionCostPer1k: 0.001,\n        currency: 'USD',\n      },\n      'bison': {\n        promptCostPer1k: 0.0005,\n        completionCostPer1k: 0.001,\n        currency: 'USD',\n      },\n    },\n  };\n\n  private baseUrl: string;\n\n  protected async doInitialize(): Promise<void> {\n    if (!this.config.apiKey) {\n      throw new AuthenticationError('Google AI API key is required', 'google');\n    }\n\n    // Use Gemini API for newer models, PaLM API for older ones\n    const model = this.config.model;\n    if (model.startsWith('gemini')) {\n      this.baseUrl = 'https://generativelanguage.googleapis.com/v1beta';\n    } else {\n      this.baseUrl = 'https://generativelanguage.googleapis.com/v1beta2';\n    }\n  }\n\n  protected async doComplete(request: LLMRequest): Promise<LLMResponse> {\n    const googleRequest = this.buildGoogleRequest(request);\n    const model = this.mapToGoogleModel(request.model || this.config.model);\n    \n    const url = `${this.baseUrl}/models/${model}:generateContent?key=${this.config.apiKey}`;\n    \n    const controller = new AbortController();\n    const timeout = setTimeout(() => controller.abort(), this.config.timeout || 60000);\n\n    try {\n      const response = await fetch(url, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify(googleRequest),\n        signal: controller.signal,\n      });\n\n      clearTimeout(timeout);\n\n      if (!response.ok) {\n        await this.handleErrorResponse(response);\n      }\n\n      const data: GoogleAIResponse = await response.json();\n      \n      if (!data.candidates || data.candidates.length === 0) {\n        throw new LLMProviderError(\n          'No response generated',\n          'NO_RESPONSE',\n          'google',\n          undefined,\n          false\n        );\n      }\n\n      const candidate = data.candidates[0];\n      const content = candidate.content.parts.map(part => part.text).join('');\n      \n      // Calculate cost\n      const usageData = data.usageMetadata || {\n        promptTokenCount: this.estimateTokens(JSON.stringify(request.messages)),\n        candidatesTokenCount: this.estimateTokens(content),\n        totalTokenCount: 0,\n      };\n      usageData.totalTokenCount = usageData.promptTokenCount + usageData.candidatesTokenCount;\n\n      const pricing = this.capabilities.pricing![request.model || this.config.model];\n      const promptCost = (usageData.promptTokenCount / 1000) * pricing.promptCostPer1k;\n      const completionCost = (usageData.candidatesTokenCount / 1000) * pricing.completionCostPer1k;\n\n      return {\n        id: `google-${Date.now()}`,\n        model: request.model || this.config.model,\n        provider: 'google',\n        content,\n        usage: {\n          promptTokens: usageData.promptTokenCount,\n          completionTokens: usageData.candidatesTokenCount,\n          totalTokens: usageData.totalTokenCount,\n        },\n        cost: {\n          promptCost,\n          completionCost,\n          totalCost: promptCost + completionCost,\n          currency: 'USD',\n        },\n        finishReason: this.mapFinishReason(candidate.finishReason),\n      };\n    } catch (error) {\n      clearTimeout(timeout);\n      throw this.transformError(error);\n    }\n  }\n\n  protected async *doStreamComplete(request: LLMRequest): AsyncIterable<LLMStreamEvent> {\n    const googleRequest = this.buildGoogleRequest(request);\n    const model = this.mapToGoogleModel(request.model || this.config.model);\n    \n    const url = `${this.baseUrl}/models/${model}:streamGenerateContent?key=${this.config.apiKey}`;\n    \n    const controller = new AbortController();\n    const timeout = setTimeout(() => controller.abort(), (this.config.timeout || 60000) * 2);\n\n    try {\n      const response = await fetch(url, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify(googleRequest),\n        signal: controller.signal,\n      });\n\n      if (!response.ok) {\n        await this.handleErrorResponse(response);\n      }\n\n      const reader = response.body!.getReader();\n      const decoder = new TextDecoder();\n      let buffer = '';\n      let totalContent = '';\n      let promptTokens = 0;\n      let completionTokens = 0;\n\n      while (true) {\n        const { done, value } = await reader.read();\n        if (done) break;\n\n        buffer += decoder.decode(value, { stream: true });\n        const lines = buffer.split('\\n');\n        buffer = lines.pop() || '';\n\n        for (const line of lines) {\n          if (line.trim() === '') continue;\n          \n          try {\n            const data: GoogleAIResponse = JSON.parse(line);\n            \n            if (data.candidates && data.candidates.length > 0) {\n              const candidate = data.candidates[0];\n              const content = candidate.content.parts.map(part => part.text).join('');\n              \n              if (content) {\n                totalContent += content;\n                yield {\n                  type: 'content',\n                  delta: { content },\n                };\n              }\n              \n              if (data.usageMetadata) {\n                promptTokens = data.usageMetadata.promptTokenCount;\n                completionTokens = data.usageMetadata.candidatesTokenCount;\n              }\n            }\n          } catch (e) {\n            this.logger.warn('Failed to parse Google AI stream chunk', { line, error: e });\n          }\n        }\n      }\n\n      // Final event with usage and cost\n      const pricing = this.capabilities.pricing![request.model || this.config.model];\n      const promptCost = (promptTokens / 1000) * pricing.promptCostPer1k;\n      const completionCost = (completionTokens / 1000) * pricing.completionCostPer1k;\n\n      yield {\n        type: 'done',\n        usage: {\n          promptTokens,\n          completionTokens,\n          totalTokens: promptTokens + completionTokens,\n        },\n        cost: {\n          promptCost,\n          completionCost,\n          totalCost: promptCost + completionCost,\n          currency: 'USD',\n        },\n      };\n    } catch (error) {\n      clearTimeout(timeout);\n      throw this.transformError(error);\n    } finally {\n      clearTimeout(timeout);\n    }\n  }\n\n  async listModels(): Promise<LLMModel[]> {\n    return this.capabilities.supportedModels;\n  }\n\n  async getModelInfo(model: LLMModel): Promise<ModelInfo> {\n    return {\n      model,\n      name: model,\n      description: this.getModelDescription(model),\n      contextLength: this.capabilities.maxContextLength[model] || 4096,\n      maxOutputTokens: this.capabilities.maxOutputTokens[model] || 2048,\n      supportedFeatures: [\n        'chat',\n        'completion',\n        ...(model.includes('vision') ? ['vision'] : []),\n        ...(model.startsWith('gemini') ? ['function_calling'] : []),\n      ],\n      pricing: this.capabilities.pricing![model],\n    };\n  }\n\n  protected async doHealthCheck(): Promise<HealthCheckResult> {\n    try {\n      const url = `${this.baseUrl}/models?key=${this.config.apiKey}`;\n      const response = await fetch(url);\n\n      if (!response.ok) {\n        throw new Error(`Health check failed: ${response.status}`);\n      }\n\n      return {\n        healthy: true,\n        timestamp: new Date(),\n      };\n    } catch (error) {\n      return {\n        healthy: false,\n        error: error instanceof Error ? error.message : 'Unknown error',\n        timestamp: new Date(),\n      };\n    }\n  }\n\n  private buildGoogleRequest(request: LLMRequest): GoogleAIRequest {\n    // Convert messages to Google format\n    const contents: GoogleAIRequest['contents'] = [];\n    \n    for (const message of request.messages) {\n      // Skip system messages or prepend to first user message\n      if (message.role === 'system') {\n        if (contents.length === 0) {\n          contents.push({\n            role: 'user',\n            parts: [{ text: `Instructions: ${message.content}` }],\n          });\n        }\n        continue;\n      }\n      \n      contents.push({\n        role: message.role === 'assistant' ? 'model' : 'user',\n        parts: [{ text: message.content }],\n      });\n    }\n\n    return {\n      contents,\n      generationConfig: {\n        temperature: request.temperature ?? this.config.temperature,\n        topK: request.topK ?? this.config.topK,\n        topP: request.topP ?? this.config.topP,\n        maxOutputTokens: request.maxTokens ?? this.config.maxTokens,\n        stopSequences: request.stopSequences ?? this.config.stopSequences,\n      },\n      safetySettings: [\n        {\n          category: 'HARM_CATEGORY_HARASSMENT',\n          threshold: 'BLOCK_NONE',\n        },\n        {\n          category: 'HARM_CATEGORY_HATE_SPEECH',\n          threshold: 'BLOCK_NONE',\n        },\n        {\n          category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n          threshold: 'BLOCK_NONE',\n        },\n        {\n          category: 'HARM_CATEGORY_DANGEROUS_CONTENT',\n          threshold: 'BLOCK_NONE',\n        },\n      ],\n    };\n  }\n\n  private mapToGoogleModel(model: LLMModel): string {\n    const modelMap: Record<string, string> = {\n      'gemini-pro': 'gemini-pro',\n      'gemini-pro-vision': 'gemini-pro-vision',\n      'palm-2': 'text-bison-001',\n      'bison': 'text-bison-001',\n    };\n    return modelMap[model] || model;\n  }\n\n  private mapFinishReason(reason: string): 'stop' | 'length' | 'content_filter' {\n    switch (reason) {\n      case 'STOP':\n        return 'stop';\n      case 'MAX_TOKENS':\n        return 'length';\n      case 'SAFETY':\n      case 'RECITATION':\n        return 'content_filter';\n      default:\n        return 'stop';\n    }\n  }\n\n  private getModelDescription(model: LLMModel): string {\n    const descriptions: Record<string, string> = {\n      'gemini-pro': 'Google\\'s most capable text model',\n      'gemini-pro-vision': 'Gemini Pro with vision capabilities',\n      'palm-2': 'Previous generation large language model',\n      'bison': 'Efficient model for various tasks',\n    };\n    return descriptions[model] || 'Google AI language model';\n  }\n\n  private async handleErrorResponse(response: Response): Promise<void> {\n    const errorText = await response.text();\n    let errorData: any;\n\n    try {\n      errorData = JSON.parse(errorText);\n    } catch {\n      errorData = { error: { message: errorText } };\n    }\n\n    const message = errorData.error?.message || 'Unknown error';\n\n    switch (response.status) {\n      case 401:\n      case 403:\n        throw new AuthenticationError(message, 'google', errorData);\n      case 429:\n        throw new RateLimitError(message, 'google', undefined, errorData);\n      default:\n        throw new LLMProviderError(\n          message,\n          `GOOGLE_${response.status}`,\n          'google',\n          response.status,\n          response.status >= 500,\n          errorData\n        );\n    }\n  }\n}"],
  "mappings": ";;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA,2BAA6B;AAC7B,mBAYO;AAsDA,MAAM,uBAAuB,kCAAa;AAAA,EAxEjD,OAwEiD;AAAA;AAAA;AAAA,EACtC,OAAoB;AAAA,EACpB,eAAqC;AAAA,IAC5C,iBAAiB;AAAA,MACf;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAAA,IACA,kBAAkB;AAAA,MAChB,cAAc;AAAA,MACd,qBAAqB;AAAA,MACrB,UAAU;AAAA,MACV,SAAS;AAAA,IACX;AAAA,IACA,iBAAiB;AAAA,MACf,cAAc;AAAA,MACd,qBAAqB;AAAA,MACrB,UAAU;AAAA,MACV,SAAS;AAAA,IACX;AAAA,IACA,mBAAmB;AAAA,IACnB,yBAAyB;AAAA,IACzB,wBAAwB;AAAA;AAAA,IACxB,gBAAgB;AAAA;AAAA,IAChB,eAAe;AAAA,IACf,eAAe;AAAA,IACf,oBAAoB;AAAA,IACpB,oBAAoB;AAAA,IACpB,kBAAkB;AAAA,IAClB,kBAAkB;AAAA,IAClB,WAAW;AAAA,MACT,mBAAmB;AAAA,MACnB,iBAAiB;AAAA,MACjB,oBAAoB;AAAA,IACtB;AAAA,IACA,SAAS;AAAA,MACP,cAAc;AAAA,QACZ,iBAAiB;AAAA,QACjB,qBAAqB;AAAA,QACrB,UAAU;AAAA,MACZ;AAAA,MACA,qBAAqB;AAAA,QACnB,iBAAiB;AAAA,QACjB,qBAAqB;AAAA,QACrB,UAAU;AAAA,MACZ;AAAA,MACA,UAAU;AAAA,QACR,iBAAiB;AAAA,QACjB,qBAAqB;AAAA,QACrB,UAAU;AAAA,MACZ;AAAA,MACA,SAAS;AAAA,QACP,iBAAiB;AAAA,QACjB,qBAAqB;AAAA,QACrB,UAAU;AAAA,MACZ;AAAA,IACF;AAAA,EACF;AAAA,EAEQ;AAAA,EAER,MAAgB,eAA8B;AAC5C,QAAI,CAAC,KAAK,OAAO,QAAQ;AACvB,YAAM,IAAI,iCAAoB,iCAAiC,QAAQ;AAAA,IACzE;AAGA,UAAM,QAAQ,KAAK,OAAO;AAC1B,QAAI,MAAM,WAAW,QAAQ,GAAG;AAC9B,WAAK,UAAU;AAAA,IACjB,OAAO;AACL,WAAK,UAAU;AAAA,IACjB;AAAA,EACF;AAAA,EAEA,MAAgB,WAAW,SAA2C;AACpE,UAAM,gBAAgB,KAAK,mBAAmB,OAAO;AACrD,UAAM,QAAQ,KAAK,iBAAiB,QAAQ,SAAS,KAAK,OAAO,KAAK;AAEtE,UAAM,MAAM,GAAG,KAAK,OAAO,WAAW,KAAK,wBAAwB,KAAK,OAAO,MAAM;AAErF,UAAM,aAAa,IAAI,gBAAgB;AACvC,UAAM,UAAU,WAAW,MAAM,WAAW,MAAM,GAAG,KAAK,OAAO,WAAW,GAAK;AAEjF,QAAI;AACF,YAAM,WAAW,MAAM,MAAM,KAAK;AAAA,QAChC,QAAQ;AAAA,QACR,SAAS;AAAA,UACP,gBAAgB;AAAA,QAClB;AAAA,QACA,MAAM,KAAK,UAAU,aAAa;AAAA,QAClC,QAAQ,WAAW;AAAA,MACrB,CAAC;AAED,mBAAa,OAAO;AAEpB,UAAI,CAAC,SAAS,IAAI;AAChB,cAAM,KAAK,oBAAoB,QAAQ;AAAA,MACzC;AAEA,YAAM,OAAyB,MAAM,SAAS,KAAK;AAEnD,UAAI,CAAC,KAAK,cAAc,KAAK,WAAW,WAAW,GAAG;AACpD,cAAM,IAAI;AAAA,UACR;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA,MACF;AAEA,YAAM,YAAY,KAAK,WAAW,CAAC;AACnC,YAAM,UAAU,UAAU,QAAQ,MAAM,IAAI,UAAQ,KAAK,IAAI,EAAE,KAAK,EAAE;AAGtE,YAAM,YAAY,KAAK,iBAAiB;AAAA,QACtC,kBAAkB,KAAK,eAAe,KAAK,UAAU,QAAQ,QAAQ,CAAC;AAAA,QACtE,sBAAsB,KAAK,eAAe,OAAO;AAAA,QACjD,iBAAiB;AAAA,MACnB;AACA,gBAAU,kBAAkB,UAAU,mBAAmB,UAAU;AAEnE,YAAM,UAAU,KAAK,aAAa,QAAS,QAAQ,SAAS,KAAK,OAAO,KAAK;AAC7E,YAAM,aAAc,UAAU,mBAAmB,MAAQ,QAAQ;AACjE,YAAM,iBAAkB,UAAU,uBAAuB,MAAQ,QAAQ;AAEzE,aAAO;AAAA,QACL,IAAI,UAAU,KAAK,IAAI,CAAC;AAAA,QACxB,OAAO,QAAQ,SAAS,KAAK,OAAO;AAAA,QACpC,UAAU;AAAA,QACV;AAAA,QACA,OAAO;AAAA,UACL,cAAc,UAAU;AAAA,UACxB,kBAAkB,UAAU;AAAA,UAC5B,aAAa,UAAU;AAAA,QACzB;AAAA,QACA,MAAM;AAAA,UACJ;AAAA,UACA;AAAA,UACA,WAAW,aAAa;AAAA,UACxB,UAAU;AAAA,QACZ;AAAA,QACA,cAAc,KAAK,gBAAgB,UAAU,YAAY;AAAA,MAC3D;AAAA,IACF,SAAS,OAAO;AACd,mBAAa,OAAO;AACpB,YAAM,KAAK,eAAe,KAAK;AAAA,IACjC;AAAA,EACF;AAAA,EAEA,OAAiB,iBAAiB,SAAoD;AACpF,UAAM,gBAAgB,KAAK,mBAAmB,OAAO;AACrD,UAAM,QAAQ,KAAK,iBAAiB,QAAQ,SAAS,KAAK,OAAO,KAAK;AAEtE,UAAM,MAAM,GAAG,KAAK,OAAO,WAAW,KAAK,8BAA8B,KAAK,OAAO,MAAM;AAE3F,UAAM,aAAa,IAAI,gBAAgB;AACvC,UAAM,UAAU,WAAW,MAAM,WAAW,MAAM,IAAI,KAAK,OAAO,WAAW,OAAS,CAAC;AAEvF,QAAI;AACF,YAAM,WAAW,MAAM,MAAM,KAAK;AAAA,QAChC,QAAQ;AAAA,QACR,SAAS;AAAA,UACP,gBAAgB;AAAA,QAClB;AAAA,QACA,MAAM,KAAK,UAAU,aAAa;AAAA,QAClC,QAAQ,WAAW;AAAA,MACrB,CAAC;AAED,UAAI,CAAC,SAAS,IAAI;AAChB,cAAM,KAAK,oBAAoB,QAAQ;AAAA,MACzC;AAEA,YAAM,SAAS,SAAS,KAAM,UAAU;AACxC,YAAM,UAAU,IAAI,YAAY;AAChC,UAAI,SAAS;AACb,UAAI,eAAe;AACnB,UAAI,eAAe;AACnB,UAAI,mBAAmB;AAEvB,aAAO,MAAM;AACX,cAAM,EAAE,MAAM,MAAM,IAAI,MAAM,OAAO,KAAK;AAC1C,YAAI;AAAM;AAEV,kBAAU,QAAQ,OAAO,OAAO,EAAE,QAAQ,KAAK,CAAC;AAChD,cAAM,QAAQ,OAAO,MAAM,IAAI;AAC/B,iBAAS,MAAM,IAAI,KAAK;AAExB,mBAAW,QAAQ,OAAO;AACxB,cAAI,KAAK,KAAK,MAAM;AAAI;AAExB,cAAI;AACF,kBAAM,OAAyB,KAAK,MAAM,IAAI;AAE9C,gBAAI,KAAK,cAAc,KAAK,WAAW,SAAS,GAAG;AACjD,oBAAM,YAAY,KAAK,WAAW,CAAC;AACnC,oBAAM,UAAU,UAAU,QAAQ,MAAM,IAAI,UAAQ,KAAK,IAAI,EAAE,KAAK,EAAE;AAEtE,kBAAI,SAAS;AACX,gCAAgB;AAChB,sBAAM;AAAA,kBACJ,MAAM;AAAA,kBACN,OAAO,EAAE,QAAQ;AAAA,gBACnB;AAAA,cACF;AAEA,kBAAI,KAAK,eAAe;AACtB,+BAAe,KAAK,cAAc;AAClC,mCAAmB,KAAK,cAAc;AAAA,cACxC;AAAA,YACF;AAAA,UACF,SAAS,GAAG;AACV,iBAAK,OAAO,KAAK,0CAA0C,EAAE,MAAM,OAAO,EAAE,CAAC;AAAA,UAC/E;AAAA,QACF;AAAA,MACF;AAGA,YAAM,UAAU,KAAK,aAAa,QAAS,QAAQ,SAAS,KAAK,OAAO,KAAK;AAC7E,YAAM,aAAc,eAAe,MAAQ,QAAQ;AACnD,YAAM,iBAAkB,mBAAmB,MAAQ,QAAQ;AAE3D,YAAM;AAAA,QACJ,MAAM;AAAA,QACN,OAAO;AAAA,UACL;AAAA,UACA;AAAA,UACA,aAAa,eAAe;AAAA,QAC9B;AAAA,QACA,MAAM;AAAA,UACJ;AAAA,UACA;AAAA,UACA,WAAW,aAAa;AAAA,UACxB,UAAU;AAAA,QACZ;AAAA,MACF;AAAA,IACF,SAAS,OAAO;AACd,mBAAa,OAAO;AACpB,YAAM,KAAK,eAAe,KAAK;AAAA,IACjC,UAAE;AACA,mBAAa,OAAO;AAAA,IACtB;AAAA,EACF;AAAA,EAEA,MAAM,aAAkC;AACtC,WAAO,KAAK,aAAa;AAAA,EAC3B;AAAA,EAEA,MAAM,aAAa,OAAqC;AACtD,WAAO;AAAA,MACL;AAAA,MACA,MAAM;AAAA,MACN,aAAa,KAAK,oBAAoB,KAAK;AAAA,MAC3C,eAAe,KAAK,aAAa,iBAAiB,KAAK,KAAK;AAAA,MAC5D,iBAAiB,KAAK,aAAa,gBAAgB,KAAK,KAAK;AAAA,MAC7D,mBAAmB;AAAA,QACjB;AAAA,QACA;AAAA,QACA,GAAI,MAAM,SAAS,QAAQ,IAAI,CAAC,QAAQ,IAAI,CAAC;AAAA,QAC7C,GAAI,MAAM,WAAW,QAAQ,IAAI,CAAC,kBAAkB,IAAI,CAAC;AAAA,MAC3D;AAAA,MACA,SAAS,KAAK,aAAa,QAAS,KAAK;AAAA,IAC3C;AAAA,EACF;AAAA,EAEA,MAAgB,gBAA4C;AAC1D,QAAI;AACF,YAAM,MAAM,GAAG,KAAK,OAAO,eAAe,KAAK,OAAO,MAAM;AAC5D,YAAM,WAAW,MAAM,MAAM,GAAG;AAEhC,UAAI,CAAC,SAAS,IAAI;AAChB,cAAM,IAAI,MAAM,wBAAwB,SAAS,MAAM,EAAE;AAAA,MAC3D;AAEA,aAAO;AAAA,QACL,SAAS;AAAA,QACT,WAAW,oBAAI,KAAK;AAAA,MACtB;AAAA,IACF,SAAS,OAAO;AACd,aAAO;AAAA,QACL,SAAS;AAAA,QACT,OAAO,iBAAiB,QAAQ,MAAM,UAAU;AAAA,QAChD,WAAW,oBAAI,KAAK;AAAA,MACtB;AAAA,IACF;AAAA,EACF;AAAA,EAEQ,mBAAmB,SAAsC;AAE/D,UAAM,WAAwC,CAAC;AAE/C,eAAW,WAAW,QAAQ,UAAU;AAEtC,UAAI,QAAQ,SAAS,UAAU;AAC7B,YAAI,SAAS,WAAW,GAAG;AACzB,mBAAS,KAAK;AAAA,YACZ,MAAM;AAAA,YACN,OAAO,CAAC,EAAE,MAAM,iBAAiB,QAAQ,OAAO,GAAG,CAAC;AAAA,UACtD,CAAC;AAAA,QACH;AACA;AAAA,MACF;AAEA,eAAS,KAAK;AAAA,QACZ,MAAM,QAAQ,SAAS,cAAc,UAAU;AAAA,QAC/C,OAAO,CAAC,EAAE,MAAM,QAAQ,QAAQ,CAAC;AAAA,MACnC,CAAC;AAAA,IACH;AAEA,WAAO;AAAA,MACL;AAAA,MACA,kBAAkB;AAAA,QAChB,aAAa,QAAQ,eAAe,KAAK,OAAO;AAAA,QAChD,MAAM,QAAQ,QAAQ,KAAK,OAAO;AAAA,QAClC,MAAM,QAAQ,QAAQ,KAAK,OAAO;AAAA,QAClC,iBAAiB,QAAQ,aAAa,KAAK,OAAO;AAAA,QAClD,eAAe,QAAQ,iBAAiB,KAAK,OAAO;AAAA,MACtD;AAAA,MACA,gBAAgB;AAAA,QACd;AAAA,UACE,UAAU;AAAA,UACV,WAAW;AAAA,QACb;AAAA,QACA;AAAA,UACE,UAAU;AAAA,UACV,WAAW;AAAA,QACb;AAAA,QACA;AAAA,UACE,UAAU;AAAA,UACV,WAAW;AAAA,QACb;AAAA,QACA;AAAA,UACE,UAAU;AAAA,UACV,WAAW;AAAA,QACb;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EAEQ,iBAAiB,OAAyB;AAChD,UAAM,WAAmC;AAAA,MACvC,cAAc;AAAA,MACd,qBAAqB;AAAA,MACrB,UAAU;AAAA,MACV,SAAS;AAAA,IACX;AACA,WAAO,SAAS,KAAK,KAAK;AAAA,EAC5B;AAAA,EAEQ,gBAAgB,QAAsD;AAC5E,YAAQ,QAAQ;AAAA,MACd,KAAK;AACH,eAAO;AAAA,MACT,KAAK;AACH,eAAO;AAAA,MACT,KAAK;AAAA,MACL,KAAK;AACH,eAAO;AAAA,MACT;AACE,eAAO;AAAA,IACX;AAAA,EACF;AAAA,EAEQ,oBAAoB,OAAyB;AACnD,UAAM,eAAuC;AAAA,MAC3C,cAAc;AAAA,MACd,qBAAqB;AAAA,MACrB,UAAU;AAAA,MACV,SAAS;AAAA,IACX;AACA,WAAO,aAAa,KAAK,KAAK;AAAA,EAChC;AAAA,EAEA,MAAc,oBAAoB,UAAmC;AACnE,UAAM,YAAY,MAAM,SAAS,KAAK;AACtC,QAAI;AAEJ,QAAI;AACF,kBAAY,KAAK,MAAM,SAAS;AAAA,IAClC,QAAQ;AACN,kBAAY,EAAE,OAAO,EAAE,SAAS,UAAU,EAAE;AAAA,IAC9C;AAEA,UAAM,UAAU,UAAU,OAAO,WAAW;AAE5C,YAAQ,SAAS,QAAQ;AAAA,MACvB,KAAK;AAAA,MACL,KAAK;AACH,cAAM,IAAI,iCAAoB,SAAS,UAAU,SAAS;AAAA,MAC5D,KAAK;AACH,cAAM,IAAI,4BAAe,SAAS,UAAU,QAAW,SAAS;AAAA,MAClE;AACE,cAAM,IAAI;AAAA,UACR;AAAA,UACA,UAAU,SAAS,MAAM;AAAA,UACzB;AAAA,UACA,SAAS;AAAA,UACT,SAAS,UAAU;AAAA,UACnB;AAAA,QACF;AAAA,IACJ;AAAA,EACF;AACF;",
  "names": []
}
